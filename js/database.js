/*
<4s> - кастомный тег для обозначения отступа в 4 пробела заменяется на &nbsp;&nbsp;&nbsp;&nbsp;
что создаёт на в тексте отступ в 4 пробела. Сделан, чтобы каждый раз не прописывать &nbsp;&nbsp;&nbsp;&nbsp;
*/

links = {
    'python': ['https://youtube.com/playlist?list=PLA0M1Bcd0w8yWHh2V70bTtbVxJICrnJHd'],
    'oop': ['https://youtube.com/playlist?list=PLA0M1Bcd0w8zPwP7t-FgwONhZOHt9rz9E',
            'https://youtu.be/TxZwqVTaCmA',
            'https://youtu.be/-6DWwR_R4Xk'],
}

answersAndQuestions = {
    'work': {
        1: {'question': 'Расскажите о себе',
            'answer': `Привет! Я разработчик с опытом более трех лет, основной стек в последнее время это <b>PYTHON</b> <b>FASTAPI</b> <b>POSTGRESQL</b> <b>REDIS</b>. так же, раньше на проектах использовал <b>DJANGO</b>,
                        из брокеров сообщений настраивал <b>RABBIT</b>, пишу тесты, владею <b>GITLAB CI/CD</b>, Grafana, Sentry, <b>DOKER</b>, <b>JENKINS</b>. Работал как с монолитом так и с микросервисной архитектурой.</br>
                        Работал как в команде состоящей из трёх человек так и когда нас 9 человек. Побывал в роли "догоняющего" и в роли куратора и наставника для новых сотрудников.</br>
                        Выступаю в роли <b>НАСТАВНИКА</b> для новых сотрудников, принимаю участие в принятии <b>АРХИТЕКТУРНЫХ РЕШЕНИЙ</b>.</br>
                        За годы работы получил репутацию ответственного специалиста, который всегда доводит начатое до конца, способен сам найти необходимую информацию, умеет наладить контакт с практически любым человеком,
                        в случае если это необходимо, всегда прихожу на помощь и не стесняюсь просить её у коллег. Сознательно практически всегда настроен на рост и развитие профессиональных навыков,
                        стремлюсь к изучению нового, люблю брать на себя ответственность за свои действия.</br>
                        Что касается нерелевантного опыта: есть успешный менеджерский опыт - год работал коммерческим директором в стартапе в сфере образования,
                        два года руководил отдела продаж в авторитейле и пять лет продавал новые машины, был опыт работы
                        на стройке, была попытка в собственный бизнес мелкий бизнес - сеть ломбардов в региональном центре`},
        15: {'question': 'Почему вы ищете новую работу?',
            'answer': `В первую очередь я гонюсь за развитием профессиональных навыков, поэтому ищу проект в котором буду использовать новые технологии
                       либо на более глубоком уровне буду использовать текущий стэк, так же интересует команда, налаженные процессы командного взаимодействия,
                       `},
        8: {'question': 'Расскажите о самом интересном своём проекте',
            'answer': `Это конечно не связано с написанием кода напрямую, но больше всего мне запомнился момент, когда компания взяла заказ на разработку
                        HRM-системы (корпоративный портал) там сложилась такая ситуации, что у лида и ПМ не было четкого понимания какой бриф нужно запросить у клиента
                        чтобы можно было сделать детальную декомпозицию проекта из-за этого процесс согласования направления развития иногда сильно затягивался (вероятно это связано с тем, что ранее брали заказы только
                        на однотипные проекты сайтов, интернет магазины и тд), в этой ситуации я впервые попробовал взять на себя больше ответственности, полез в архитектуру, мы вместе составили бриф,
                        который заполнял клиент, конечно им пришлось взять паузу, самим видимо финализировать многие моменты, но после фиксации полной структуры, мы смогли взяться за работу и согласовывали только самые мелкие детали,
                        впоследствии заполнение брифа вошло в один из пунктов чек-листа работы с клиентом и применяется до сих пор, постоянно дорабатывается.`},
        4: {'question': 'Расскажите о самом большом своём факапе',
            'answer': `Во многом благодаря моему гипертрофированному перфекционизму, а так же грамотному эстимейту ничего критичного не происходило, но из того что запомнилось...
                        была ситуация, когда мой код вместо даты отдавал на фронт timestamp: фронт ожидал дату, не парсил её соответствие. В результате в прод выкатили так, что пользователи видели таймстэмп
                        как только мы заметили, сразу же пофиксил и в итоге такое поведение было где 40-60 минут, после этого происшествия я лобировал код-ревью даже на "лёгкие" задачи, с тех пор код мы проверяем друг за другом
                        даже за синьёром!`},
        5: {'question': 'Опишите свой последний рабочий проект',
            'answer': `Уведомления о изменении цен на парфюмерию: Разработал систему для отправки уведомлений и оповещений юзерам, например: электронной почте, телеграмм. Создал крон, который вытягивал из базы данных
                        определенные значения и запускал в установленное время отправку сообщения пользователям. Телеграм просто через бота отправлял, на которого подписаны юзеры. А почту через MailGun через базу адресов.<br>
                        <br>
                        <strong>Надежный способ успокоить интервьюера - сказать 70% времени разрабатывал новый функционал, 20% - багфиксы и продумывание архитектуры, 10%  митинги и бюрократия</strong>`},
        6: {'question': 'Опишите какая была команда и стек на последнем месте',
            'answer': `Работает много человек, разработчиков около 100. В команде бэк разработки примерно 30 человек.
                        На каждый проект выделяют определенное количество разработчиков, поэтому количество людей в команде меняется постоянно. Раньше на нескольких проектах были ситуации что несколько разрабов
                        подключаются на время, например наш тимлид, пара мидлов, а джуны со стороны, на последних двух проектах работал исключительно своей командой: 1 тимлид, 1 синьёр, 4 мидла, 3 джуниора.<br>
                        Фреймворк - FastAPI<br>
                        Репозиторий - gitlab. Использовали ci/cd. Я не настраивал и просто использовал.<br>
                        Базы данных - использовали Postgres, Redis<br>
                        Postgres - для хранения бизнес логики<br>
                        Redis - для хранения кэша<br>
                        ClickHouse - аналитика<br>
                        SQL - SQLAlcheamy<br>
                        Логирование - kibana<br>
                        Отслеживание ошибок - Sentry<br>
                        Метрика и графики - Grafana<br>
                        Для поднятия сервера использовали k8s, Jenkins.<br>
                        API - Rest Full API<br>
                        Дока API - swagger<br>
                        Тестирование - pytest<br>
                        Task Manager - Jira<br>
                        Внутренняя дока - confluence`},
        7: {'question': 'Опишите как был устроен рабочий процесс на последнем месте работы',
            'answer': `Работаем по канбану. Задачи берем сами в Jira из колонки (ready for dev). Когда только пришёл, то задачи мне давал тимлид. Можно было брать максимум 3 задачи в разработку в один момент.<br>
                        <br>
                        Берёшь таску из Jira -> создаёшь Feature ветку -> пишешь код -> отправляешь мерж-реквест в ветку Dev -> апрув мердж-реквеста -> в ходе пайплайна код проходит е2е тесты, юнит-тесты, линтеры,
                        git-линтеры и собирается образ бэка, фронта -> ветка Feature вливается в Dev -> при релизе из Dev создается ветка, все собирается в Jenkins и выкатывается в Kubernetes<br>
                        <br>
                        Как происходило общение между командой?<br>
                        В слаке, а затем в каналах в mattermost. Если лично нужно было пообщаться, то в телеграмме. Так же созванивались в google meet.<br>
                        <br>
                        Кто занимался тестированием?<br>
                        Ты писал юнит тесты кода, который ты написал. Тестировщик проверял задачу руками при мердж реквесте. # Юнит тесты всегда сам разработчик пишет, а тестировщик руками уже всё проверяет и тестирует интеграционными
                        `},
        10: {'question': 'Какие ваши ожидания от нового места работы?',
            'answer': `Можно сказать, что ищешь интересный проект с достойной зарплатой и развитием по хардскилам и карьере.<br>

                        `},
        9: {'question': 'По каким критериям будете выбирать из нескольких офферов?',
            'answer': `Можно сказать, что в первую очередь будешь смотреть на то насколько интересный проект и на зарплату,
                       затем какое развитие могут предложить (по хардскилам и по карьере), если всё перечисленное примерно
                       одинаковое, то выберешь более известную компанию.`},
        3: {'question': 'ЛЕГЕНДА, ВОПРОСЫ О ТЕКУЩЕМ МЕСТЕ РАБОТЫ - не технические',
            'answer': `
                        Что-то изменил бы?<br>
                        Заменил бы daily митинга на еженедельный созвон в понедельник (по скраму), ввёл бы онбординг для новых сотрудников<br>
                        <br>
                        Нравится ли руководство? (или вопрос сформулированный по другому, имеющий такой же смысл)<br>
                        В целом всё хорошо, коммуникация проходила легко, всегда можно подойти с вопросом или предложением. Как мне видится, процессы могли быть более лучше налажены, но это стартап и меня всё устраивает.<br>
                        <br>
                        Что нравилось или не нравилось на предыдущем месте работы?<br>
                        Тут надо смотреть в какую компанию откликаешься:<br>
                        <strong>- если это крупная компания</strong>, где отлажены процессы, то: не особо нравилась организация, иногда мог сидеть и ждать пока дадут задачу, могли сказать на словах, что делать, а только потом
                        описывать в notion.
                        Не было постоянного код ревью. Нравилось, что опыт работы с хорошим сеньером и мидлами, которые помогали и подсказывали, работа с новыми технологиями.<br>

                        <strong>- если это мелкая компания</strong>, где может не быть чёткого распределения, то: нравилось что сам мог решать и находить проблемы, возможность привносить свои идеи,
                        маленький коллектив, в котором легко коммуницировать.
                        Не нравилось - тут аккуратней, маленькие компании не любят когда тебе вдруг, что-то может не понравится).<br>
                        <br>

                        `},
        11: {'question': 'Опишите самую интересную задачу с которой сталкивались',
            'answer': `Нужно было автоматизировать процесс формирования сложного отчета и отправки его результатов с определенной периодичностью, передо мной стояла задача разработать и запустить крон, документации не было,
                        добавлю, что я столкнулся с проблемой медленной загрузки данных статистики, т.к. они очень объемные. Погуглив несколько часов, проанализировал ситуацию, что данные формировались за прошлый период и не изменялись,
                        а их нужно было извлекать несколько раз, принял решение использовать рэдис для кэширования и ставил отметку, по какой период данные там хранятся. Соответственно ночью кроном дергал
                        при формировании отчета объемную часть данных
                        дергал из кэша, а новые (начиная с установленной отметки) запрашивал из постгри, но их было не много. Таким образом кроном я разгрузил БД и сделал возможным доступ к отчету по кнопке.`},
        12: {'question': 'Каким достижением на прошлой работе вы можете гордиться?',
            'answer': `В компании не было юнит-тестирования. Я провел анализ подходящих фреймворков, подготовил материалы, рассказал всем на презентации и начал обучать людей. Практику успешно внедрили и теперь
                        она повсеместно используется, я бы очень хотел как-то оцифровать это улучшение, но подобные метрики у нас никто не собирает.`},
        13: {'question': 'Что вы изучаете в последнее время? Как следите за последними тенденциями в разработке? Что полезного и нового вы узнали по своей профессии за последний год?',
            'answer': `Тут добавлю инфу из файла`},
        14: {'question': 'Расскажите о ситуации, когда вы не укладывались в сроки',
            'answer': `Считаю что такие ситуации нормальны в нашей работе. Часто приходиться работать с задачами высокой неопределенности и тут главное держать в курсе команду и заинтересованные стороны.
                        Когда подобные ситуации происходят, я рассказываю о проблеме команде и руководителю, дальше решаем, нужно ли привлечь помощь, изменить сроки или упростить задачу.
                        Например, перенести часть функционала в следующий релиз.<br>
                        <br>
                        Ключевые шаги, при сорванных сроках:<br>
                        1. Оценить новый срок и учесть ошибки<br>
                        2. Предупредить руководителя<br>
                        3. Предложить конкретные действия:<br>
                           а. Привлечь помощь<br>
                           б. Работать сверхурочно<br>
                           в. Договориться и сдвинуть срок<br>
                           г. Изменить постановку задачи, состав работ<br>
                           д. Отказаться от менее приоритетных задач<br>
                        4. Предупредить людей, чья работа зависит от завершения вашей работы<br>
                        5. Первым делом брать в работу ту часть задачи, которая самая рискованная и непроработанная.<br>
                        `},
        2: {'question': 'ЛЕГЕНДА, ВОПРОСЫ О ТЕКУЩЕМ МЕСТЕ РАБОТЫ - технические',
            'answer': `Каким образом распределялись задачи?<br>
                        Самостоятельно брал из Jira из колонки ready for dev. Так же иногда могли дать конкретную задачу от тимлида.<br>
                        <br>
                        Был ли код ревью?
                        Код ревью при легких задачах можно было пропустить. При средних и сложных задачах обязательный код-ревью при мердж реквесте.<br>
                        <br>
                        Как работали с бд?<br>
                        Драйвер для подключения к постгресу - psycopg2. В коде использовали орм SQLAlcheamy, иногда  для выборки данных и парсинга сторонних сервисов - чистый SQL. Для работы с бд использовал DBеaver.<br>
                        <br>
                        Работал ли с докером, деплоем приложения?<br>
                        Да, деплоил через jenkins и контролировал поднятие подов внутри кубов.
                        <br>
                        Как была реализована работа с гитом?<br>
                        Проект хранился в основной репе. На каждую задачу заводилась ветка и потом мержили её в две ветку. Иногда можно было запросить код ревью, мердж реквест выполнял сеньор. Конфликты решал самостоятельно.<br>
                        <br>
                        Были ли поставлены сроки на выполнение задачи?<br>
                        Задачи имели сложность (1-5) и в соответствии с этой сложностью имелось представление сколько занимает времени выполнение задачи. Выполнял в основном всё быстро и в срок. Если возникали трудности,
                        то озвучивали это на daily митингах.<br>
                        <br>
                        Было ли реализовано логирование, отслеживание ошибок, метрика?<br>
                        Логирование я настраивал в кебана. Ошибки падали в sentry, но так как проект пока не увидел свет реальные данные пока не выехали, так что пока смотрели там ошибки с тестового стенда.
                        Метрика была выведена в графану.<br>
                        <br>
                        Как общался бэк и фронт?<br>
                        Rest API. В основном фронт смотрел всё в свагере.<br>
                        <br>
                        Какие задачи решал?
                        Типы задач: <br>

                        1) Простые<br>
                        >>>Написание юниттестов написанного кода # Здесь особо ничего не нужно пояснять. Писал тесты для своего кода при помощи модуля pytest
                        >>>Создание документации для проекта и бэкенда # дока для апи генерировалась сама в сваггер. Сам ты писал доку в конфлюенс для различных вводимых тобой фич. Например, ты описал как работает авторизация, как пользоваться отчетом и т.д.
                        >>>Фикс багов # всякая мелочь. Например, отдавали timestamp вместо даты, при скачивании отчета на маке ломалась кодировка и т.д.
                        2) Средние<br>
                        >>>Проектирование схем бд, создание и оптимизации запросов, также управление миграциями данных. # проектирование бд понятно. Оптимизация запросов - были запросы, где искались данные в большой табличке по дате
                        и искалось долго, ты решил тем, что навесил индекс на дату. Миграции применял после обновления моделей, тут тоже вроде ясно.
                        >>>Разработал функционал для создания, редактирования и удаления учетных записей пользователей, управления их ролями и правами доступа. # Тут реализовал, дополнил модель юзера, создал нужные пермиты и рестрикшены
                        и выдавал допуск в определенным ресурсам в соотв.  с ними.
                        3) Сложные<br>
                        >>>Аутентификация и авторизация: Разработал систему аутентификации и авторизации пользователей, включая использование токенов и сессий. # Здесь внедрил использование x-csrf токенов. Токен генерируется на сервера
                        и включается в каждый запрос, отправляемый от юзера на сервер. Этот токен связан с конкретной сессией юзера и конкретным действием. Когда сервер получает запрос, он проверяет, соответствует ли токен ожидаемому
                        значению, и отклоняет запрос, если токен не совпадает или отсутствует.
                        >>>Уведомления и оповещения: Разработал систему для отправки уведомлений и оповещений юзеров, например: электронной почте, телеграмм # Здесь создавал крон, который вытягивал из базы данных определенные значения
                        и запускал в установленное время отправку сообщения пользователям. Телеграм просто через бота отправлял, на которого подписаны юзеры. А почту через MailGun через базу адресов.
                        >>>Отчеты и аналитика: функционал для создания отчетов и аналитики по данным о сотрудниках, их производительности и т.д. # вкладка со статистикой. Ты соотв. Написал бэк для этой ручки. Когда обращаются к стате,
                        то скрипт собирает данные с постгреса, аккумулирует их и отдаёт в нужном формате. Юзер может задавать поля, фильтры, даты и т.д.
            `},
        16: {'question': 'Если бы мы попросили ваших коллег рассказать про вас, чтобы мы услышали? Как бы описали вас другие разработчики / менеджеры проектов, с которыми вы работали?',
            'answer': `Я переодически спрашиваю об этом своего менеджера, тим лида, а так же ментора. Получаю развернутый и конструктивный фидбек.
                        Им нравится то, что я постоянно развиваюсь; ответственно отношусь к свои задачам и срокам по ним; всегда готов помочь коллегам`},
    },
    'python': {
        1: {'question': 'Ссылки на материалы для изучения',
            'answer': `1) <a href="${links['python'][0]}" target="_blank">Курс по Python</a> от Сергея Балакирева<br>`},
        6: {'question': 'Мутабельные - иммутабельные объекты',
            'answer': `изменяемый - неизменяемый<br>
чтобы сделать класс иммутабельным, нужно объявить в инит все атрибуты, сделать их приватными, не использовать методы изменения объектов (сеттеры), а только геттеры,
если свойства класса являются изменяемыми объектами (списки, словари) то предоставлять копии этих объектов:<br>
class ImmutableClass:<br>
    <4s>def __init__(self, prop1, prop2):<br>
        <4s><4s>self._prop1 = list(prop1)<br>
        <4s><4s>self._prop2 = dict(prop2)<br><br>

    <4s>def get_prop1(self):<br>
        <4s><4s>return self._prop1<br>

    <4s>def get_prop2(self):<br>
        <4s><4s>return self._prop2 `},
        7: {'question': 'Сериализация и десериализация данных',
            'answer': `Сериализация - процесс преобразования данных из одного формата в другой, так чтобы они могли быть переданы по сети или сохранены на диске.<br><br>
Процесс преобразования данных в последовательность байтов так, чтобы они могли быть сохранены или переданы между системами. <br>словарь  --->  json строку DUMPS<br><br>
Десериализация - преобразование байтовой последовательности в исходные данные и объекты. <br>json ---> словарь LOADS<br><br>
Обычно используется для обмена информацией между приложениями либо для сохранения объектов или данных на диск. JSON XML PROTOBUF MESSAGESPACK`},
        8: {'question': 'Что такое замыкание?',
            'answer': `Замыкание - это концепция, которая существует во многих языках программирования и позволяет
                        функции запоминать и использовать переменные из своей объемлющей области видимости даже после
                        того, как эта область видимости уже неактивна. Например:<br>
                        def outer_function(x):<br>
                        <4s>def inner_function(y):<br>
                        <4s><4s>return x + y<br>
                        <br>
                        <4s>return inner_function<br>
                        <br>
                        <br>
                        closure = outer_function(10)<br>
                        result_1 = closure(5)<br>
                        result_2 =  closure(10)<br>
                        print(result_1, result_2)<br>
                        <br>
                        В консоль будет выведено:<br>
                        15<br>
                        20<br>
                        <br>
                        Так происходит потому, что переменная closure хранит ссылку на функцию inner_function, которая в
                        свою очередь обращается к переменной x, т.е. имеет неявную скрытую ссылку на своё глобальное
                        окружение (на локальное окружение родительской функции outer_function, которое мы создали
                        при её вызове). Таким образом, так как имеется ссылочная связь по цепочке, то сборщик мусора не
                        удаляет переменную x.`},
        24: {'question': 'Как работает сборщик мусора в Python?',
            'answer': `В пайтон существует автоматический сборщик мусора, который отслеживает количество ссылок на объекты и удаляет объекты, когда счетчик ==0. при создании объекта создается счетчик со значением 1.
                       <br><br>
                       В Python используется разновидность сборщика мусора, называемая "генерационным". Он разделяет
                       объекты на три поколения: молодое поколение, поколение следующего уровня и долгоживущие объекты.
                       Большинство объектов быстро становятся мусором и собираются в молодом поколении, но если они
                       переживают несколько сборок мусора, то перемещаются в поколение следующего уровня для более
                       тщательной обработки.`},
        4: {'question': 'Как в Python устроены словари?',
            'answer': `В Python словари (dict) устроены как хеш-таблицы, что делает их очень эффективными для быстрого
                       поиска и доступа к данным. В словарях представлены данные в виде ключей и значений, где каждый
                       ключ должен быть уникальным.
                       <br><br>
                       При добавлении элемента в словарь, Python использует хеш-функцию для определения индекса, по
                       которому он должен храниться. При поиске элемента Python повторно использует эту хеш-функцию для
                       поиска индекса, что делает поиск элементов в словаре очень быстрым. По этой же причине в качестве
                       ключа можно использовать только хэшируемый тип данных.
                       <br><br>
                       Словари в Python являются изменяемым типом данных, что означает, что они могут изменяться в
                       процессе выполнения программы. Они также являются контейнерным типом данных, что позволяет
                       хранить в них любые другие типы данных, включая списки, кортежи и даже другие словари.`},
        3: {'question': 'Как в Python устроены списки?',
            'answer': `Списки - упорядоченный массив элементов, списки относятся к изменяемому типу, списки могут хранить в себе объекты разных типов. <br><br>
особенности: динамическое выделение памяти, списки хранят элементы в массиве (быстро получаем элемент по индексу, но добавление в центр -->> смещает другие), списки изменяемы, списки индексируемы.`},
        2: {'question': 'Типы данных в Python',
            'answer': `-чистовые: инт, флоат, децимал, комплексные, фракшнс<br>
-строковый<br>
-логический <br>
-списки<br>
-кортежи<br>
-словари<br><br>
неизменяемые = строки, кортежи, числа, логический тип, фрозенсет<br>
изменяемые = списки, словари, множества<br><br>
хэшируемые = строки, числа, кортежи, фрозенсэт, булевы значения, None
`},
        9: {'question': 'Что такое вещественные и ссылочные типы данных?',
            'answer': `Вещественный - тип данных, которые хранятся непосредственно в памяти, каждая переменная имеющая вещественный тип, хранит "значение" непосредственно в себе.<br>
вещественные типы данных копируются при присваивании, таким образом, если мы создаём копию переменной с вещественных значением, то она будет содержать точную копию, а не ссылку на оригинал.<br><br>
Пример: целые и вещественные числа, логический тип, нан.<br><br>
Ссылочные - представляют собой объекты, которые хранят ссылки на область памяти, где фактически хранятся данные; значит что при присваивании значения, в переменной хранится ссылка на объект, а не сам объект;
когда создаете копию на объект вы копируете ссылку на область в памяти и обе переменных будут ссылаться на неё.<br><br>
Пример: списки, строки, словари, кортежи, множества, пользовательские объекты и классы`},
        10: {'question': 'Что такое List Comprehensions?',
            'answer': `Компактный способ генерации списков, применяя выражение к каждому элементу в итерируемом объекте, например в другом списке и фильтруя элементы основываясь на условии.`},
        11: {'question': 'Генератор (yield) и Моржовый оператор',
             'answer': `Это специальный тип функции, который позволяет создавать итерируемые объекты без необходимости хранить сразу все значения в памяти, они генерируются функцией по мере необходимости и возвращаются при помощи yield.<br>
Когда функция содержит ключевое слово yield она "превращается" в генератор, замораживает текущее состояние и возвращает значение, но не завершает функцию.<br><br>
Генераторы - особый вид итераторов, использовать стоит для объектов, которые не могут быть сохранены в памяти одновременно.<br>
<b>Yield from</b> - полезен при работе с вложенными итерируемыми объектами. - Позволяет делегировать выполнение другому генератору, создавая цепочку генераторов, которые могут быть остановлены и возобновлены в любой момент.<br>
Генераторы - производят значения для итерации, <b>Корутины</b> - могут потреблять значения отправленные в них.<br><br>
ДО:<br>
def flatten(nested_list):<br>
    <4s>for sublist in nested_list:<br>
        <4s><4s>for item in sublist:<br>
            <4s><4s><4s>yield item<br>
ПОСЛЕ:<br>
def flatten(nested_list):<br>
    <4s>for sublist in nested_list:<br>
        <4s><4s>yield from sublist<br>
nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]<br>
print(list(flatten(nested_list)))<br><br>
Используются для ленивой загрузки, при повторном вызове, функция начинает с того места где остановилась, используются в местах где ожидается итерируемый объект, отдаёт значения "налету" - полезно с большими объемами данных<br><br><br>
Моржовый оператор - Когда мы присваиваем значение переменной и тут же вощзвращаем её значение:<br>
print(num := 15)`},
        12: {'question': 'Что такое декораторы в Python? Как написать свой декоратор?',
            'answer': `Особый вид функций, которые позволяют дополнить функционал другой функции, не изменяя её исходный код.<br>
Создаешь функцию, которая принимает на вход другую функцию и возвращает её без вызова, иннер принимает агрс и кваргс, реализует интерфейс и возвращает результат.<br>
Часто - замер времени работы функций или подписи до начала отработки и после завершения.<br><br>
def measure_time(func):<br>
    <4s>def wrapper(*args, **kwargs):<br>
        <4s><4s>start_time = time.time()<br>
        <4s><4s>result = func(*args, **kwargs)<br>
        <4s><4s>end_time = time.time()<br>
        <4s><4s>print(f"Время выполнения: {end_time - start_time} секунд")<br>
        <4s><4s>return result<br><br>
    <4s>return wrapper<br><br><br>
@measure_time<br>
def slow_function():<br>
    time.sleep(2)<br>
    print("Замедленная функция")<br><br><br>
slow_function()
`},
        23: {'question': 'Какие есть изменения в версиях Python 2.x/3.x?',
             'answer': `- print был оператором, а стал функцией, было print "Hello, world"<br>
- деление / целых чисел, раньше возвращало целое число, как // сейчас, сейчас число с плавающей точкой<br>
-xrange --> range<br>
-next стал встроенной функцией, был методом итераторов<br>
-удалён raw_input<br>
-в обработке исключений добавлен блок AS<br>
-long объединён с int<br>
-zip стал возвращать итератор, а не список<br>
-asyncio с версии 3.х, с 3.5 async/await<br>
-метод super() стал удобнее и точнее<br>
-3.х предоставляет синтаксис для аннотаций типов<br><br><br>
             Версия 2.2 (21 дек 2001):<br>
                        - классам добавлен базовый класс object<br>
                        Версия 3.4 (16 мар 2014):<br>
                        - добавлена библиотека asyncio (асинхронность)<br>
                        Версия 3.5 (13 сен 2015):<br>
                        - добавлена библиотека typing (аннотация типов)<br>
                        Версия 3.8 (21 окт 2019):<br>
                        - добавлен моржовый оператор (:=)<br>
                        Версия 3.10 (4 окт 2021):<br>
                        - добавлено перечисление типов через знак | (может использоваться например в аннотации типов
                        или в проверке isinstance())<br>
                        - улучшена безопасность (труднее декомпозировать exe-файл в исходный python-код)<br>
                        - добавлена конструкция match-case`},
        14: {'question': 'Что делает функция enumerate?',
            'answer': `Предоставляет лёгкий способ перебирать элементы итерируемого объекта вместе с их индексами.<br> Возвращает кортежи содержащие индекс и элемент.<br><br>
fruits = ['apple', 'banana', 'cherry']<br>
<br><br>
for index, fruit in enumerate(fruits):<br>
    print(f"Index {index}: {fruit}")<br>
            `},
        15: {'question': 'Что делает функция zip?',
            'answer': `Позволяет комбинировать элементы из нескольких итерируемых объектов в кортежи. <br/> Возвращает итератор, который генерирует кортежи, содержащие пары элементов с одинаковыми индексами из каждого из входных итер.`},
        16: {'question': 'Как в Python отловить ошибку?',
        'answer': `try/except в блоке try код, в except ожидаемая ошибка, можно несколько блоков эксепт, еще есть finally выполняется всегда, можно туда логику зашить.`},
        17: {'question': 'Что такое распаковка в Python?',
             'answer': `Распаковка в Python - это процесс извлечения элементов из последовательностей (словарей,
                        кортежей или списков) и присвоения их переменным. В Python для распаковки последовательностей
                        используются операторы * и ** для кортежей и словарей соответственно. Оператор * распаковывает
                        последовательность и передает отдельные элементы в функцию в качестве отдельных аргументов (в
                        случае словаря - ключи), а оператор ** распаковывает словарь и передает его значения по ключу.
                        Распаковка может использоваться для удобного прохода по элементам последовательностей, передачи
                        аргументов в функции или присваивания значений переменным в одной строке кода. Например:<br>
                        my_list = (1, 2, 3)<br>
                        a, b, c = *my_list<br>
                        print(a, b, c)<br>
                        В консоль будет выведено 1, 2, 3<br>
                        <br>
                        или<br>
                        <br>
                        my_dict = {'a': 1, 'b': 2, 'c': 3}<br>
                        d, e, f = **my_dict<br>
                        print(d, e, f)<br>
                        В консоль будет выведено 1, 2, 3<br><br>
                        Еще можно * обозначить "всё остальное" при распаковке<br>
a=[1,2,3,4]<br>
b, *rest = a`},
        18: {'question': 'Зачем нужна конструкция if __name__ == "__main__"?',
             'answer': `в файле может быть код, который не обёрнут в функцию (находится в глобальной области видимости), при запуске файла такой код выполнится. <br>Однако, файл не всегда используется как исполняемый файл,
             но и как хранилище (модуль) если такой файл импортируется в другой модуль, и запускается через конструкцию ифнейммейн, то код не обернутый в функции не будет выполнен.<br>
Так же эта конструкция упрощает ручное тестирование, можно вносить в нее отдельные функции и запускать`},
        19: {'question': 'Что такое args и kwargs в Python?',
             'answer': `В Python это специальные параметры, которые позволяют передавать различное количество аргументов
                        в функцию.<br>
                        <br>
                        - args - это параметр функции, который позволяет передавать переменное количество позиционных
                        аргументов. Имя args может быть любым, но обычно используется именно args. Параметр args
                        представляется в виде кортежа (tuple) и позволяет передавать неограниченное количество аргументов
                        позиционно. Функция может распаковать этот кортеж и обрабатывать каждый аргумент отдельно.
                        Пример использования *args:<br>
                        def my_function(*args):<br>
                        <4s>for arg in args:<br>
                        <4s><4s>print(arg)<br>
                        <br>
                        my_function(1, 2, 3)<br>
                        <br>
                        <br>
                        Будет выведено в консоль:<br>
                        1<br>
                        2<br>
                        3<br>
                        <br>
                        kwargs - это параметр функции, который позволяет передавать переменное количество именованных
                        аргументов. Имя kwargs может быть любым, но обычно используется именно kwargs. Параметр kwargs
                        представляется в виде словаря (dictionary) и позволяет передавать неограниченное количество
                        именованных аргументов. Функция может использовать этот словарь для доступа к каждому аргументу
                        по имени. Пример использования **kwargs:<br>
                        def my_function(*args):<br>
                        <4s>for arg in args:<br>
                        <4s><4s>print(arg)<br>
                        <br>
                        <br>
                        my_function(1, 2, 3)<br>
                        Вывод:<br>
                        1<br>
                        2<br>
                        3`},
        20: {'question': 'Какие типы параметров есть в Python?',
             'answer': `1) Позиционные параметры - обрабатываются в той же последовательности в которой описаны в сигнатуре функции<br>
2) Именованые параметры - возможность передавать параметры с именами, делая вызов более явным<br>
3) Параметры со значением по умолчанию<br>
4) Переменное количество эаргументов<br>
Все кроме позиционных являются опциональными при вызове функции.<br><br><br>
             В функциях Python есть 4 типа параметров:<br>
                        1) Позиционные параметры - значения таким аргументам присваиваются в той последовательности, в
                        которой они объявлены в функции<br>
                        2) Именованные параметры - параметры, которые значения в которые передаются по имени параметра.<br>
                        3) *args - параметр с переменным количеством позиционных аргументов. Параметр args представляется
                        в виде кортежа (tuple) и позволяет передавать неограниченное количество аргументов позиционно.
                        Функция может распаковать этот кортеж и обрабатывать каждый аргумент отдельно.<br>
                        4) *kwargs - параметр с переменным количеством именованных аргументов. Параметр kwargs
                        представляется в виде словаря (dictionary) и позволяет передавать неограниченное количество
                        именованных аргументов. Функция может использовать этот словарь для доступа к каждому аргументу
                        по имени.<br>
                        <br>
                        Все параметры кроме позиционных являются опциональными, т.е. необязательными при вызове функции.
                        В Python параметры разных видов имеют установленный порядок - они должны располагаться в том же
                        порядке, в каком описаны выше.`},
        21: {'question': 'В чём отличие global от nonlocal?',
             'answer': `global - говорит о том что переменная относится к глобальному скоупу, даёт возможность изменять значения переменной изнутри функции.<br>
nonlocal - говорит, что переменная относится внешнему уровню вложенности, к скоупу родительской функции. должно быть взято значение оттуда, а не создавать новое.<br><br><br>
             В Python ключевое слово global означает, что переменная относится к глобальной области видимости
                        за пределами всех функций, а ключевое слово nonlocal означает, что переменная относится к внешнему
                        уровню вложенности функции, например когда одна функция объявлена внутри другой, то объявление переменной
                        с ключевым словом nonlocal означает, что обращение идёт к переменной в области видимости
                        родительской функции.<br>
                        Пример с global:<br>
                        a = 1<br>
                        def my_function(a):<br>
                        <4s>a += 1<br>
                        def my_other_function(a):<br>
                        <4s>global a<br>
                        <4s>a += 1<br>
                        <br>
                        my_function(2)<br>
                        print(a)<br>
                        my_other_function(5)<br>
                        print(a)<br>
                        <br>
                        Будет выведено:<br>
                        1<br>
                        2<br>
                        <br>
                        Так произошло потому, что нельзя изменять глобальную переменную внутри функции без объявления её
                        как global, соответственно в первой функции произошло обращение к локальной переменной с тем же
                        именем (а если бы не было локальной переменной с таким именем, то произошла бы ошибка). А во
                        второй функции уже есть указание, что следует обращаться именно к переменной за пределами функции,
                        соответственно её значение изменилось.<br>
                        <br>
                        Пример с nonlocal:<br>
                        def counter_1(start=0):<br>
                        <4s>def step():<br>
                        <4s><4s>nonlocal start<br>
                        <4s><4s>start += 1<br>
                        <4s><4s>return start<br>
                        <br>
                        <4s>return step<br>
                        <br>
                        <br>
                        def counter_2(start=0):<br>
                        <4s>def step():<br>
                        <4s><4s>start += 1<br>
                        <4s><4s>return start<br>
                        <br>
                        <4s>return step<br>
                        <br>
                        <br>
                        c1 = counter_1()<br>
                        print(c1)<br>
                        c2 = counter_2()<br>
                        print(c2)<br>
                        <br>
                        После вызова функции counter_1 её результат будет присвоен переменной и выведен в консоль, а при
                        вызове функции counter_2 возникнет ошибка. Так происходит, потому что в первой функции мы явно
                        указали, что к переменной нужно обращаться в родительской области видимости, а во второй функции
                        такого указания нет и функция пытается найти переменную в локальной области видимости и не
                        находит (в глобальной области даже не ищет, потому что без ключевого слова global изменение
                        глобальных переменных запрещены).`},
    13: {'question': 'Что такое ХЭШ?',
         'answer': `В Python хэш - это числовое значение, вычисляемое для любого объекта по определённому алгоритму.
                    В Python для вычисления хэша используется функция hash(). В Python хэш используется например в
                    словарях, для каждого ключа вычисляется хэш и уже он используется для получения соответствующего
                    значения из хэш-таблицы (это сильно ускоряет код, так как для получения данных по хэшу есть
                    специальный алгоритм). Важные замечания про хэш:<br>
                    - если два объекта равны, то у них будет одинаковый хэш, т.е. если object_1 == object_2, то и
                    hash(object_1) == hash(object_2)<br>
                    - если у двух объектов одинаковый хэш, это не обязательно означает, что они равны. С очень маленькой
                    вероятностью хэш может совпасть у разных объектов. Т.е. если hash(object_1) == hash(object_2), то
                    необязательно object_1 == object_2.<br>
                    - если у двух объектов разные хэши, то объекты точно не равны. Т.е. если hash(object_1) != hash(object_2),
                    то object_1 != object_2.<br>
                    - хэш можно вычислять только для неизменяемых объектов (иначе получим ошибку)<br><br>
                    Варианты решения коллизий:<br>
                    - хранить не один элемент, а список элементов, односвязный список.`},
    22: {'question': 'ДЛЯ ВСТАВКИ',
            'answer': ``},
    5: {'question': 'Контекстные менеджеры - под капотом.',
            'answer': `Чтобы создать свой контекстный менеджер в Python, вам необходимо определить класс, который содержит методы __enter__() и __exit__()<br>
            или с помощью функции не создавая класс обернуть декоратором @contextmanager описывать логику через try except finally.<br>
            Какую логику можно зашивать в контекстный менеджер?<br>
            Контекстный менеджер помогает 1. освободить ресурсы - закроет файл или соединение (with db.helper.session_factory()) даже если упадёт исключение и логика не будет выполнена. 2. инкапсулировать и переиспользовать логику трай ексепт файнали.<br>
            Какую-либо хитрую отработку исключений, логирование, какие-то уведомления.<br><br>
class ResourceWorker:<br>
    <4s>def __init__(self, *args):<br>
        <4s><4s>self.args = args<br>
        <4s><4s>self.resource = None<br><br>

    <4s>def __enter__(self, ):<br>
        <4s><4s>self.resource = Resource()<br>
        <4s><4s>self.resource.open(*self.args)<br>
        <4s><4s>return self.resource<br><br>

    <4s>def __exit__(self, exc_type, exc_val, exc_tb):<br>
        <4s><4s>if self.resource:<br>
            <4s><4s><4s>self.resource.close()<br><br><br>
            @contextmanager<br>
def open_resource(*args):<br>
    <4s>resource=None<br>
    <4s>try:<br>
        <4s><4s>resource=Resource()<br>
        <4s><4s>resource.open(*args)<br>
        <4s><4s>yield resource<br>
    <4s>except Exception:<br>
        <4s><4s>#log<br>
        <4s><4s>raise<br>
    <4s>finally:<br>
        <4s><4s>if resource:<br>
            <4s><4s><4s>resource.close()
            `},
    },
    'async': {
        1: {'question': 'Что такое asyncio?',
            'answer': `Asyncio (Asynchronous Input/Output) - это библиотека для написания асинхронного кода с
                       использованием синтаксиса async/await в Python. Она предоставляет асинхронную основу для многих
                       Python фреймворков, использующих асинхронное программирование. Благодаря asyncio можно
                       одновременно обрабатывать большое количество запросов, обращаться к внешним сервисам и
                       улучшить производительность веб-приложений.<br><br>
                       <a href="https://habr.com/ru/articles/667630/" target="_blank">Асинхронный python без головной боли (часть 1)</a><br>
                       <a href="https://habr.com/ru/articles/774582/" target="_blank">Асинхронный python без головной боли (часть 3)</a>
                       `},
        2: {'question': 'Что такое async и await? !! Теперь не gather a TaskGroup !!',
            'answer': `async и await - это ключевые слова, используемые при работе с асинхронными функциями в Python.<br> async
                       помечает функцию как асинхронную, а await используется для ожидания результата работы функции.
                       `},
        3: {'question': 'Зачем нужно асинхронное выполнение кода?',
            'answer': `В контексте backend-разработки очень много времени тратится на операции ввода-вывода данных
                       (input/output), асинхронное выполнение кода нужно для того, чтобы выполнять такие операции
                       параллельно. К примеру, чтобы запросы к базе данных не замедляли выполнение кода и выполнялись
                       параллельно остальному коду или когда микросервисы посылают запросы к другим сервисам.`},
        8: {'question': 'Для каких задач применяется asynсio в Django проекте?',
            'answer': `Асинхронный ввод-вывод, предоставляемый asyncio, позволяет одновременно обрабатывать большое
                       количество запросов, не блокируя основной поток выполнения. В Django можно использовать asyncio
                       для обработки запросов, в работе которых требуется обращение к внешним сервисам, например, при
                       отправке электронной почты, обращении к API сторонних сервисов, работы с веб-сокетами и т.д.`},
        5: {'question': 'Многопроцессорность, многопоточность, асинхронность. В чём между ними разница и где что лучше использовать? Как реализуются в Python?',
            'answer': `Многопроцессорность в Python реализуется через библиотеку multiproccesing.<br>
многопроцессорность - использует отдельные процессы, каждый из которых обладает своей памятью и интерпретатором, что позволяет параллельно выполнять код<br><br>
Многопоточность в Python реализуется через библиотеку threading.<br>
многопоточность - использует потоки, которые совместно используют рессуры процесса. из-за GIL, только 1 поток может выполняться в один момент<br><br>
Асинхронность в Python реализуется через библиотеку asyncio.<br>
асинхронный подход позвоняет максимально эффективно пользоваться ресурсами одного потока, работая с нескольки операциями, переключаясь между ними в моменты ожидания.<br><br>
            Минусы многопроцессорности:<br>
                       - требуют много памяти (особенно для Python)<br>
                       - неэффективная коммуникация между процессами<br>
                       - overhead со стороны OS (user-space to kernel-space trip, scheduling, context switching),
                       тратится слишком много ресурсов, например вычищение кэшей при context switching<br>
                       <br>
                       Многопоточность имеет преимущества над многопроцессорностью:<br>
                       - требует меньше памяти<br>
                       - между потоками коммуникация более эффективная и простая чем между процессами (так как общая память)<br>
                       - менее ресурсозатратное переключение между потоками (не нужно чистить кэши)<br>
                       <br>
                       Но так же имеет ряд минусов:<br>
                       - иные проблемы с коммуникацией между потоками - состояние гонки, дедлоки (из-за общей памяти)<br>
                       - всё ещё overhead со стороны OS (шедулинг потоков)<br>
                       - даже если ограничивать количество потоков пулами, то пулы всё равно могут забиваться, приложение зависает<br>
                       `},
       6: {'question': 'Что такое GIL?',
            'answer': `GIL (Global Interpreter Lock) - это механизм в CPython (стандартной реализации Python), который
                       предназначен для обеспечения потокобезопасности, ограничивая выполнение кусков байткода Python
                       только одним потоком в любое время.
                       <br><br>
                       GIL блокирует объект интерпретатора, что позволяет только одному потоку Python выполнять байткод
                       в конкретный момент времени. Это нужно для того, чтобы гарантировать, что изменения в памяти не
                       приводят к недопустимым состояниям, таким как гонки данных или состояния гонок, т.е. для защиты
                       структуры данных интерпретатора, который имеет глобальную область видимости.
                       <br><br>
                       Вследствие этого GIL может ограничивать производительность многопоточных приложений. Хотя многие
                       операции в Python, такие как ввод-вывод или работа с сетью, могут проходить без блокировки GIL,
                       многопоточные приложения, к примеру, производящие вычисления, в большинстве случаев не получают
                       ощутимого преимущества от использования нескольких потоков.
                       <br><br>
                       Некоторые реализации Python, такие как Jython и IronPython, не имеют GIL и опираются на другие
                       механизмы для обеспечения потокобезопасности.`},
       4: {'question': 'Инжектор fastapi.',
            'answer': `Объекты больше не создают друг друга и не получают доступ к друг другу НАПРЯМУЮ. Но они предоставляют способ сделать инъекцию зависимости внутрь себя.<br>
                        1. Инъекция в конструктор - параметрами в __init__, когда объект создаётся, передаём туда зависимости.<br>
                        Чтобы не дублировать кучу кода в рантайме приложения мы будем использовать фреймворк Dependency Injector, там берем контейнеры и провайдеры.<br>
                        Есть ощущение, что в фастапи тоже самое реализует библиотека Depends?`},
       7: {'question': 'Отличие task от future? Awaitable бъекты: корутина, таск, футура.',
            'answer': `Task - это задача, поставленная циклу событий корутиной, одновременно являющаяся Future, которая представляет собой результат выполнения Таск в будущем.<br>
                    ensure_future() принимает любые awaitable объекты, а create_task() только корутину.<br>
                    Task - подкласс Future. Task - это Future, который фактически был запущен для вычисления и привязан к циклу событий.<br>
                    Отличие в состоянии и реализации: Таск - конкретная асинхронная задача, которая уже запланирована для выполнения,
                    а Футура - потенциальный результат асинхронной операции, который может быть выполен в будущем.`},
    },
    'databases': {
        1: {'question': 'Что такое ACID?',
        'answer': `
Набор характеристик, которые отображают надёжность и целостность транзакций в базах данных.<br>
Атомарность (Atomicity): Транзакция считается выполненной целиком или не выполненной вообще. Нет промежуточных состояний. Если хотя бы одна операция в транзакции не выполнится, то все изменения откатываются.<br>
Согласованность (Consistency): Транзакция должна приводить базу данных из одного согласованного состояния в другое согласованное состояние. Это означает, что данные всегда находятся в корректном состоянии с учётом всех ограничений и правил.<br>
Изоляция (Isolation): Транзакции, выполняющиеся параллельно, не должны влиять друг на друга. Каждая транзакция должна иметь видимость только к собственным изменениям до их завершения.<br>
Долговечность (Durability): После успешного завершения транзакции её результаты должны сохраняться на носителе даже в случае сбоя системы.<br><br>
Масштабирование БД:<br>
репликация (копирование бд), гео-распределение, master-slave (пишем изменения в мастер, он высылает отчет слейвам) синхронная и асинхронная реплики, распределение нагрузки (чтение не с головной бд), OLTP | OLAP<br><br>
состояние гонки - ситуация при параллельном выполнении операций, когда результат зависит от того, какая будет выполнена первой. избежать можно используя принципы синхронизации: блокировки, семафоры, мониторы - обеспечивают последовательное выполнение операций.<br><br>
реализовать принцип атомарности в sql можно командами BEGIN TRANSACTION, COMMIT, ROLLBACK
`},
        11: {'question': 'Radis',
        'answer': `Опенсорс проект, который используется как, инмемори база данных, кэш и брокер сообщений, написана на языке Си<br>
                    Можно поднимать в докере, можно на локалхосте.<br>
                    <br>
                    import radis<br>
                    <br>
                    redis_client = redis.Redis(host="localhost", port=6379, db=0)<br>
                    <br>
                    redis_client.close()`},
        12: {'question': 'Clickhouse',
        'answer': `Запрос делаем по колонке (а не ищем по строкам, а затем по столбцам) и данные записаны будут записаны в памяти послдеовательно.`},
        6: {'question': 'CAP теорема.',
            'answer': `Здесь вопрос максимально актуален для распределенных систем.<br><br>
            <b>C - consistency</b> - согласованность. Система в любой момент времени имеет согласованное состояние. Нужно перед тем как отправить ответ об успешной записи данных пользователю отправить обновленные данные на второй сервер бд.<br><br>
            <b>A - availability</b> - доступность. Система должна полноценно функционировать, даже если часть её узлов недоступны. Если узел упал, значит запрос должен быть перенаправлен на работающий узел, есть лоадбэлансеры, которые чекают жизнеспособность узлов.<br><br>
            <b>P - partitioning</b> - устойчивость к секционированию. Если связь между отдельными узлами нарушена, то система должна норально функционировать. <br>`},
        5: {'question': 'Отличия SQL и NoSQL?',
            'answer': `1) разные модели данных: таблицы + ключи VS  разные типы - документы, KV значения, графы, столбцы<br>
2) разный подход к масштабированию: реляционные - чаще вертикальное, за счет увелиения мощности сервера. Нереляционные - чаще горизонтальное<br>
3) схема данных. Р - имеют строгую схему, которая определяет типы данных и ограничения для каждого столбца и таблицы. НР - могут не иметь схемы или иметь динамическую схему данных<br>
4) транзакционные свойства - Р - обеспечивают ACID. НР - могут предоставлять ограниченные гарантии согласованности = BASE<br>
5) области применения. Р - хорошо подходят для сложных запросов и аналитики. НР - для работы с большими объемами данных и в условиях где гибкая схема и горизонтальное масштабирование - приоритет.`},
        3: {'question': 'Какие существуют базы данных?',
            'answer': `- Реляционные (RDBMS) Примеры: MySQL, PostgreSQL, Oracle Database, Microsoft SQL Server модели типа - таблицы и отношений между таблицами (нормализация, индексы, денормализация),
                        работа со значениями ведется по строкам, условно ищем соответствие строка + столбец<br><br>
      - NoSQL, примеры: MongoDB, Cassandra, Redis, Couchbase - пары ключ+значение, ключ уникален, а значение любого типа<br><br>
      - Time-Series, примеры: InfluxDB, OpenTSDB - бд временных рядов - для данных с отметками времени<br><br>
      - Graph , примеры: Neo4j, Amazon Neptune - это больше про то "как связаны" между собой данные, имеют узлы и рёбра, которые описывают связь между данными (типо вместо отдельных таблиц связей в эскуэль)<br><br>
      - Документо-ориентированные базы данных, примеры: MongoDB, CouchDB - условно документы, которые хранят наборы пар KV значений, не структурированы и не требуют схему, можно собирать в коллекции,
                        а из них составлять логическую иерархию, получая что-то типо реляционных бд<br><br>
      - Колоночные, примеры: Apache Cassandra, HBase, ClickHouse - колоночные ключ-значение, но в значении можно хранить несолько столбцов сразу, нет схемы,
                        значит можно хранить разные неструктурированные данные + работаем со столбцами = меньше обращений для выборки данных<br><br>
      - In-Memory, примеры: Redis, Memcached, Tarantool - хранилище данных в виде пар ключ-значение, весь массив данных хранится в RAM памяти (объемы меньше, скорость выше)<br><br>
      Чтобы увеличивать скорость и масштабируемость sql нужно делать это по вертикали или делать копии бд, для nosql можно разделять базу между связанными по сети машинами<br>
sql по скорости ниже но выше надежность, проще сделать бэкап, nosql быстрее, но более тщательно нужно следить за решением конфликтов и надежностью<br>
"+" NoSQL = лучшая масштабируемость, быстрая разработка<br>
"-" NoSQL = у каждой свой язык запросов, сильная привязка к одной субд<br><br>
BASE - "гарантии" NoSql<br>
базовая доступность - гарантия того, что каждый запрос в конечном счете завершится (+ / - )<br>
гибкое состояние - система может менять своё состояние, даже без ввода новых данных - для достижения согласования данных<br>
согласованность в конечном счете - данные могут быть не согласованы какое-то время. но в итоге приходят к согласованию через какое-то время<br><br>
инмемори - лучше подходят когда нужна низкая задержка доступа к данным, для работы с информацией, которая хранится в оперативной памяти,
работают в разы быстрее, разгружают БД. кэширование, счетчики и статистика (за счет атомарности), сессии и сеансы чаты и системы реального времени
(за счет поддержки списков и множеств), очереди задач, временные данные игровых приложений (очереди, счетчики), кэш между микросервисами.<br><br>
реляционные - это про связи таблиц, взаимоотношения, выборку нескольких элементов. электронная коммерция, системы управления контентом, пользователями,
авторизация, системы работы с задачами-статусы, сроки, приоритет, ответственные, системы аналитики и отчетности,системы управления складом.<br><br>
колоночные - отлично подходят для обработки больших объемов информации в реальном времени. системы сбора и анализа логов, анализ активности пользователей (кликов),
BIсистемы, аналитические отчеты и дашборды, агрегация и анализ данных о производительности или маркетинговых данных.<br><br>
документо-ориентированные, монго (байнари джейсон) - хороша там, где нужна гибкая схема данных и масштабируемость. блоги и соцсети, хранение контента статьи-фото-видео,
игровые сессии профили, рейтинги, системы управления каталогами и инвентарём- данные о продуктах их хар-ки и доступность
`},
        4: {'question': 'Что такое транзакция?',
             'answer': `Транзакция - логическая операция, включающая в себя одно или несколько упорядоченных действий с БД. <br>Предназначена для выполнения этих действий как единого целого либо роллбэка в противном случае`},
        7: {'question': 'Индексы в БД? Какие типы индексов бывают?',
            'answer': `Индекс реализован в виде древовидной структуры - <b>сбалансированного дерева</b>.<br><br>
            Без индекса будет осуществлен полный перебор всех строк таблицы.<br>
            С индексом, "запрос" сначала найдет значение индекса, а потом применит его для  быстрого поиска всей строки с данными.<br><br>
            1) Кластеризованные (строка связанная со значением ключа - хранится в самом индексе) - все значения отсортированы, может быть только один в таблице.<br><br>
            2) Некластеризованные (содержит !указатель! на реальные данные в таблице).<br><br>
            <b>План по оптимизации скорости запроса:</b><br>
            * EXPLAIN (explain plan - анализ стоимости запроса рассписано по этапам выполнения sql -запроса, explain-analyze - с реальным запросом в БД + ВРЕМЯ выполнения запроса.<br>
            * Проверить правильность составления запроса, не запрашиваем ли данные. которые в дальнейшем не используем и нет ли проблемы N+1.<br>
            * Навесить индексы или составные индексы.<br>
            * Ищем Non-SURGable функции и заменяем. Функции, которые не работают с индексами, тк создают специальный элемент для себя, а индексы у нас навешены на полные данные столбца.<br>
            Например, нужны данные за январь, функция EXTRACT превратит данные из столбца с датами в цифру 1 и будет использовать, нам стоит заменить в запросе на WHERE 31.12.2021 < created_at < 31.01.2022.
            Плюсы:<br>
                       - значительно ускоряют операции выборки и извлечения данных<br>
                       <br>
                       Минусы:<br>
                       - замедляют процессы обновления, добавления, вставки данных в базу, так как база требует обновления индексов<br>
                       - увеличивают размер базы данных, индексы занимают дополнительное место<br>
                       <br>
                       Индексировать следует лишь те поля, по которым точно будет производиться поиск, чтобы излишне не
                       замедлять базу и не увеличивать её размер.<br><br>
                       B-tree - сбалансированное дерево, подходит для индексирования данных, которые подлежат сравнению "больше-меньше" и есть возможность упорядочевания.<br>
                       GiST (R-деревья) - для хранения геоданных или геометрических объектов - данные которые нет смысла упорядочевать.<br>
                       SP-GiST (kd деревья) - позволяет создавать несбалансированные деревья, для хранения непересекающихся объектов.<br>
                       GIN (RUM) - полезны для организации полнотекстового поиска.
                       `},
        8: {'question': `Шардирование//реплицирование баз данных, способы масштабирования бд?`,
            'answer': `Репликация - создание полной копии базы данных = мастер + слэйв. Запись на мастер, чтение со слейва.<br>
            устанавливаем соединении с той и с другой:<br>
            master = mysql_connect('10.10.0.1', 'root', 'pwd');<br>
            slave = mysql_connect('10.10.0.2', 'root', 'pwd');<br>
            и INSERTы направляем на мастер, а SELECTы на слэйв.<br>
            <br>
            Шардинг - разделение (партиционирование) БД на отдельные части, таким образом, чтобы каждую из них можно было вынести на отдельный сервер - распределяем нагрузку.<br>
            Каждая такая таблица называется шардом. Например: Юзеры, фото1, фото2.<br>
            Шардинг выполняется прямо в приложении. Бывает горизонтальным и вертикальным.<br>
            Вертиканый - выделение таблицы или группы таблиц на отдельный сервер и для каждого шарда устанавливаем отдельное соединение.<br>
            Горизонтальный - разделение одной таблицы на разные сервера, для огромных таблиц. Например четные нечетные пользователи идут за фото и в соответствии с этим устанавливаем коннект.<br>
`},
        9: {'question': 'Какие типы JOIN есть в SQL?',
            'answer': `- INNER JOIN<br>
                       - LEFT JOIN<br>
                       - RIGHT JOIN<br>
                       - FULL OUTER JOIN<br>
                       - CROSS JOIN<br>
                       - SELF JOIN<br>`},
        10: {'question': 'Есть две таблицы - на 10 и на 5 записей. Сколько записей станет при CROSS JOIN объединении? А при INNER JOIN?',
             'answer': `1) 10*5 = 50 все варианты для каждой записи<br>
2) тут зависит от условий объединения и от совпадающих значений ключевых полей, поэтому от 0 до 5<br>`},
        2: {'question': 'Уровни изоляции БД?',
             'answer': `Это разграничение прав между параллельными транзакциями на доступ к общим ячейкам базы данных.
                        Выделяют 4 уровня изоляции:<br>
                        - Read Uncommitted (RU) - транзакция может читать данные, изменяемые другими незафиксированными
                        транзакциями, что может привести к чтению "грязных" данных<br>
                        - Read Committed (RC) - транзакция может читать только данные, зафиксированные в базе данных на
                        момент чтения или после, если данные были закоммичены<br>
                        - Repeatable Read (RR) - транзакция не будет видеть изменения, сделанные другими транзакциями
                        после начала чтения, что может привести к фантомным чтениям<br>
                        - Serializable (SE) - транзакции выполняются последовательно, что гарантирует изоляцию транзакций
                        и отсутствие фантомных чтений<br><br>
                        проблемы параллельной работы с данными:<br>
-потерянное обновление - первый что-то записал, второй это перезаписывает, а первый об этом не знает<br>
-грязное чтение - первый что-то изменяет в базе данных, второй считывает промежуточные данные, первый откатывает, а второй уже работает с прочитанными данными<br>
-неповторяющееся чтение - первый считывает данные в длительной транзакции, второй может внести в них какие-то изменения, но первый этого не увидит, увидит только при повторном запросе<br>
-фантомное чтение - первый считывает данные в длительной транзакции, второй может добавить или удалить данные, но первый этого не увидит, увидит только при повторном запросе<br><br>
уровни изоляции БД:<br>
рид анкомитед - изоляции видят результаты других незавершенных транзакций, nolock, редко используется, даёт гарантию того, что все начатые транзакции будут выполнены последовательно<br>
рид камитет - параллельные транзакици видят только зафиксированные изменения других транзакций, блокирует строки на чтение, гарантирует что параллельные транзакции не считают "недописанные" данные<br>
репитбл рид - не видны апдейт и делит других транзакций, гарантирует, что незафиксированные данные не будут прочитаны и данные, находящиеся в обработке, не будут прочитаны, работаем со "слепком" данных<br>
сериалайзбл - блокирует чтение и изменение<br><br>`},
        14: {'question': 'Как в SQL-запросах использовать CTE, группировки, агрегации?',
             'answer': `1) CTE Common Table Expression - возможность формировать временные наборы данных именованных под запрос, которая может быть использована внутри основного запроса.<br>
2) можно использовать для анализа данных внутри групп и вычеслять согрегированные значения, функции AVG/COUNT/MIN/MAX оператор GROUP BY.<br><br>
WITH CustomerOrders AS (<br>
    <4s>SELECT customers.name, SUM(orders.total) as total_orders<br>
    <4s>FROM customers<br>
    <4s>JOIN orders ON customers.id = orders.customer_id<br>
    <4s>GROUP BY customers.name<br>
)<br>
SELECT * FROM CustomerOrders;<br><br>
Результат запроса с CTE:<br>
<br>
sql<br>
+------------+-------------+<br>
| name       | total_orders|<br>
+------------+-------------+<br>
| John Smith | 70.00       |<br>
| Jane Doe   | 30.00       |<br>
| Bob Johnson| NULL        |<br>
+------------+-------------+<br>
`},
        13: {'question': 'В чём заключается проблема в ORM системах, которая называется N + 1?',
             'answer': `Проблема возникает в ORM системах при выполнении запросов к таблицам, содержащим отношения один ко многим или многие ко многим.
             Название N+1 обозначает что для выполнения запросов к N объектам в таблице нужно будет выполнить N дополнительных запросов.<br>
Предположим у нас есть объект А со связью 1ко многим с объектом Б, мы хотим получить все объекты А со связанными значениями объекта Б, в таком случае мы можем сначала получить все объекты А,
а затем, для каждого объекта А дополнительно запрашивать связанные значения объекта Б.<br><br>
Решение - использовать жадную загрузку EAGER LOADING или предварительную загрузку PRELOADING - когда мы указываем ORM вместе с основным запросом, загрузить все связанные данные.<br><br>
             Проблема N+1 в ORM (Object-Relational Mapping) системах возникает, когда при доступе к связанным
                        объектам происходит большое количество запросов к базе данных, что может привести к неэффективности
                        и плохой производительности.<br>
                        <br>
                        N+1 означает, что основной запрос выполняется один раз для получения основных данных, а затем
                        для каждого полученного объекта выполняется дополнительный запрос для загрузки связанных данных.
                        Это может происходить, например, когда у вас есть сущность "Заказ" и каждый заказ имеет связь с
                        сущностью "Клиент". Если вы запрашиваете список заказов, а затем для каждого заказа отдельно
                        запрашиваете данные о клиенте, то возникает проблема N+1.

                        Проблема N+1 может приводить к следующим негативным эффектам:<br>
                        - избыточное количество запросов к базе данных, что может вызывать задержки и негативно влиять
                        на производительность вашего приложения<br>
                        - загрузка большого объема данных, которые могут не понадобиться<br>
                        - потеря преимуществ, которые могут предоставлять более эффективные запросы, объединяющие
                        связанные данные<br>
                        <br>
                        Одним из способов решения проблемы N+1 является использование механизмов предварительной
                        загрузки (eager loading), предоставляемых ORM системами. Предварительная загрузка позволяет
                        сделать единственный запрос, чтобы получить все необходимые данные, включая связанные объекты.`},
       15: {'question': 'Разница между View и Materialized View в PostgreSQL: При использовании базы данных PostgreSQL, каковы основные отличия между View и Materialized View? ',
             'answer': `Вью - виртуальная таблица, созданная на основе выполнения запроса к одной или нескольким реальным таблицам. не хранит данные непосредственно,
             а реализует виртуальное представление, которые можно прочитать буд-то бы это была реальная таблица;<br><br>
             Характеристики:<br>
Мгновенное обновление данных; Обычно вью не может быть изменена, чаще предназначен только для чтения данных. Так же, тратит ресурсы, тк осуществляет запросы к реальным таблицам.<br><br>

Материалазед вью - по сути является копией результата запроса к реальной таблице, обновляется по мере необходимости.<br><br>
Характеристики:<br>
Можно обновлять вручную или автоматически при помощи расписания; запросы дешевле, особенно сложные`},
        16: {'question': 'Триггеры в БД.',
            'answer': `Триггеры - множество действий, которое запускается, когда выполняется одна из указанных операций изменения данных в указанной таблице.<br>
                        Полезны при валидации данных вставляемых в таблицу или при ведении аудита (логи всех данных вставляемых в таблицу).<br>
                        Вызов можно настроить на команды (INSERT, UPDATE, DELETE, TRUNCATE) выполнять можно BEFORE или AFTER, а так же INSTEAD_OF при работе с представлениями.<br>
                        В Постгрес есть два типа триггеров: ROW LEVEL (триггеры уровня записи) STATEMENT LEVEL (триггеры уровня выражения).<br>
                        ROW LEVEL - указывает, должен ли триггер процедуры быть выполнен для каждой записи, которая затронута событием триггера?<br>
                        STATEMENT LEVEL - выполняется 1 раз для 1 SQL выражения.<br>
                        В общем, там синтаксис создания триггера, вносим параметры, создаем функцию, которая будет выполняться при срабатывании...профит.`},
        17: {'question': 'ЗАДАЧИ ПО операциям над БД',
            'answer': `1. Дано:<br>
                        Есть огромный объем данных (маркетплейс-например инфо о товарах, размеры и тд), который нужно обновлять два раза в день каждый день, шардирование партицирование не доступно, обойтись без инфраструктурных приколов, имеем только Постгрю.<br>
                        Решение:<br>
                        Сделать талицуА и таблицуБ, например четные/нечетные, держать флажок переключатель, который роутит приложение либо в А либо в Б.
                        Пришли данные, смотришь какое хранилище используется и идешь в другое, там делаешь Транкейт, вставляешь данные и флажок доступа переключаешь.:<br>:<br>
                        TRUNCATE - действует как DELETE, но не сканирует все таблицы и медленно освобождает дисковое пространство, так что VACUUM после него делать не нужно.`},
    },
    'algorithms': {
        1: {'question': 'Что такое Big O?',
            'answer': `Это понятие из анализа алгоритмов в программировании. Используется для оценки сложности выполнения операций в зависимости от размера входных данных - предполагая "худший" случай.<br><br>
            Как сильно будет замедляться выполнение алгоритма при увеличении входных данных. В расчет не берутся действия, которые выполняются только один раз, учитываются только циклические действия.<br>

            Различают сложность "по времени" и сложность "по памяти"<br><br>
логарифм по основанию 2  - степень, в которую нужно возвести 2 чтобы получить число<br><br>
а почему по основанию 2 - для бинарного поиска? потому что на каждой итерации диапазон сокращается в 2 раза<br><br>
-O(log n) - логарифмическое время - бинарный поиск<br>
-O(n) - линейное время - простой поиск<br>
-O(n * log n) - эффективные алгоритмы сортировки (быстрая сортировка)<br>
-O(n *2) - медленные алгоритмы (сортировка выбором)<br>
-O(n!) - очень медленные алгоритмы`},
        2: {'question': 'Какие алгоритмы сортировки существуют?',
            'answer': `-Сортировка пузырьком (Bubble Sort): Этот алгоритм сравнивает пары соседних элементов и меняет их местами, если они находятся в неправильном порядке. Этот процесс повторяется до тех пор, пока массив не будет отсортирован.<br>
-Сортировка выбором (Selection Sort): Алгоритм поочередно выбирает минимальный элемент из оставшихся и обменивает его с первым неотсортированным элементом.<br>
-Сортировка вставками (Insertion Sort): Этот алгоритм строит отсортированную последовательность, постепенно вставляя элементы из исходного массива в правильную позицию.<br>
-Сортировка слиянием (Merge Sort): Этот алгоритм использует стратегию "разделяй и властвуй". Он разбивает массив на подмассивы, сортирует их отдельно, а затем объединяет в один отсортированный массив.<br>
-Быстрая сортировка (Quick Sort): Ещё один алгоритм "разделяй и властвуй". Он выбирает элемент (пивот), разбивает массив на две части - элементы, меньшие пивота, и элементы, большие пивота, а затем рекурсивно сортирует каждую из этих частей.<br>
-Пирамидальная сортировка (Heap Sort): Этот алгоритм строит пирамиду (или кучу) из элементов массива, а затем поочередно извлекает наибольший элемент и восстанавливает кучу.<br>
-Сортировка подсчётом (Counting Sort): Подходит для сортировки целочисленных массивов с ограниченным диапазоном значений.<br>
-Блочная сортировка (Bucket Sort): Разбивает массив на равные интервалы (блоки), сортирует каждый блок отдельно, а затем объединяет результаты.`},
        6: {'question': 'Какая сложность у операции вставки в середину списка в Python?',
            'answer': `Вставка элемента в середину списка в Python занимает O(n) времени в худшем случае, где n - это
                       длина списка. Так как после вставки элемента необходимо перепривязать все соседние элементы, что
                       может потребовать прохождения до середины списка.`},
        10: {'question': 'Какая сложность у операции вставки в конец списка в Python?',
            'answer': 'В Python сложность вставки в конец списка будет O(1).'},
        5: {'question': 'Очередь - о структуре данных. FIFO first in first out.',
            'answer': `Простейшую очередь можно реализовать с помощью библиотеки dequeue (double ended queue).<br><br>
            Есть методы: ВСЕ ОПЕРАЦИИ ЗА O(1)<br>
            append и pop - элемент в конце списка<br>
            appendleft и popleft - в начало списка<br>
            <br><br>from collections import dequeue<br><br>
            queue = dequeue(['Маша', 'Петя', 'Вася',])<br>
            queue.append('Коля') = Скорость выполнения O(1)<br>
            queue.append('Света')<br>
            queue.popleft()<br>
            Так и будет удалять первый добавленный.
            когда появляется какая сложность`},
        4: {'question': 'Что такое хэш-таблица?', 'answer': `Используются для организации данных в ассоциативных массивах. Используют индексированный массив и хэширование ключей для быстрого доступа.<br>
            Хэширование - операция, которая преобразует (hashCode) ключ в индекс массива (числовое значение). ХТ позволяют выполнять операции записи, чтения и удаления за О(1). ХТ в питоне словари и множества.<br>
            Алгоритм создания и операциЙ на ХэшСета:<br>
            hash_set = set() - создается по умолчанию из 5 бакетов.<br>
            hash('Витя') - функция вызывает для записи данных в ХС, преобразует данные в число, например 21.<br>
            Чтобы решить в какой бакет записывать данные, от этого числа находится остаток от деления, 21 % 5 = 1, значит в 1.<br>
            Таким же образом осуществляется поиск элемента - получаем от него хэшкод, а по нему индекс элемента.<br><br>
            Коллизии можно решать разными способами: Метод цепочек и Открытая адресация.<br>
            Метод цепочек - создает цепочки элементов в одной ячейке хэш-таблицы.<br>
            Открытая адресация - 3 варианта: Линейное пробирование: последовательная проверка ячеек до нахождения свободной.<br>
Квадратичное пробирование: проверка ячеек с использованием квадратичной последовательности.<br>
Двойное хеширование: использование двух хеш-функций для определения следующей ячейки в случае коллизии<br>
<br>Что то тут еще есть про __eq__ ли isEqual но лень искать.
            `},
        7: {'question': 'Как развернуть связный список (linked list)?',
            'answer': `class ListNode:<br>
    <4s>def __init__(self, val=0, next=None):<br>
        <4s><4s>self.val = val<br>
        <4s><4s>self.next = next<br><br>
<4s>def reverse_linked_list(head):<br>
    <4s><4s>prev = None<br>
    <4s><4s>current = head<br><br>
    <4s><4s>while current is not None:<br>
        <4s><4s><4s>next_node = current.next<br>
        <4s><4s><4s>current.next = prev<br>
        <4s><4s><4s>prev = current<br>
        <4s><4s><4s>current = next_node<br><br>
    <4s><4s>return prev<br><br>

Инициализируем prev (предыдущий узел) как None, а current (текущий узел) как головной узел.<br>
Затем в цикле выполняем следующие шаги:<br>
Сохраняем указатель на следующий узел, чтобы не потерять его.<br>
Меняем указатель текущего узла так, чтобы он указывал на предыдущий узел (инвертируем указатели).<br>
Перемещаем prev к текущему узлу и current к следующему узлу.<br>
По завершении цикла current будет указывать на None, что означает конец оригинального списка. prev будет указывать на новый головной узел.`},
        8: {'question': 'Как развернуть словарь в Python?',
            'answer': `Тут надо спрашивай, что нужно сделать? Поменять местами ключи и значения?<br>
            Тогда:<br>
            inverted_dict = {v: k for k, v in alpha_ru.items()}<br><br>
            Можно через преобразование к списку итемы словаря, сортед или реверс, оборачиваем в ордереддикт<br><br>
from collections import OrderedDict<br><br>
original_dict = {'b': 2, 'a': 1, 'c': 3}<br>
reversed_dict = OrderedDict(reversed(list(original_dict.items())))<br>
print(reversed_dict)<br>
            Можно через указатели:<br>
            def reversed_dict():
            <4s>current_node = my_dict: Здесь current_node устанавливается как начальный узел связанного списка.<br>
<4s>new_pointer = None: new_pointer инициализируется как None, что означает, что начально у нас нет нового указателя.<br>
<4s>while current_node:: Начинается цикл, который будет выполняться, пока current_node не станет None.<br>
<4s>old_pointer = current_node['next']: Здесь сохраняется ссылка на следующий узел в переменной old_pointer.<br>
<4s>current_node['next'] = new_pointer: Устанавливается новый указатель текущего узла, который теперь будет указывать на new_pointer (инвертируя указатели).<br>
<4s>new_pointer = current_node: new_pointer теперь указывает на текущий узел.<br>
<4s>current_node = old_pointer: Переходим к следующему узлу.<br>
<4s>return new_pointer: возвращает новый головной узел, который указывает в противоположном направлении.`},
        9: {'question': 'Связанный список. Список - это?',
            'answer': `Список - ячейки с набором индексов и связей - ссылок на данные.<br>
            Структура данных, которая представляет из себя последовательность элементов, каждый из которых, содержит данные и ссылку на следующий элемент в списке.<br>
            Для создания: Создаём класс узла, который имеем ссылку на следующий узел и класс списка, который имеет ссылку на первый узел.<br>`},
        3: {'question': 'Сложность вставки в различные структуры данных. Разобраться в структурах данных.ЗАПОЛНИТЬ',
            'answer': `<b>Списки:</b><br>
            Вставка в конец О(1)<br>
            Вставка в начало и середину О(n)<br>
            Получение элемента по индексу и получение длины спискаО(1)
            <b>Массивы: </b>
            <b>Словари: </b></b>
            Итерация - быстрее всего по списку.`},
    },
    'tests': {
        1: {'question': 'AAAЗАПОЛНИТЬ',
            'answer': ``},
        2: {'question': 'Какие инструменты для тестирования существуют?',
            'answer': `- библиотека pytest и unittest<br>
                       - Postman и curl для тестирования API<br>
                       - Selenium для автоматизации ручного тестирования<br>
                       - Linter и Black для проверки Code Style
                       - мок и мэджикмок (возвращает экземпляры - двойники) - создание поддельных объектов`},
        3: {'question': 'Какие виды тестирования существуют в backend проектах на Python?',
            'answer': `1. Модульное тестирование - проверка отдельных функций, методов, классов, модулей на их работоспособность - пайтест, юниттест<br>
2. Интеграционное тестирование - проверка взаимодействия между отдельными компонентами и службами бэкенд системы, может включать проверку взаимодействия с БД и АПИ<br>
3. Функциональное тестирование - проверка работоспособности приложения вцелом - Selenium<br>
4. АПИ тестировние - проверка работоспособности и корректности работы апи интерфейсов Postman, requests<br>
5. Нагрузочное тестирование - проверка пропускной способности и масштабируемости бэкенд системы, а так же ее реакция на высокие нагрузки Locust, Apache JMeter<br>
6. Тестирование безопасности - проверка на налчие уязвимостей и обеспечение безопасности системой. тут OWASP ZAP или Burp Suite<br>
7. Тестирование на уровне баз данных - корректность работы с БД, прогонка записи, чтения и тд в БД<br>
8. Тестирование на уровне интерфейсов - тесты пользовательского интерфейса`},
        4: {'question': 'Что такое unit-тесты? Зачем они нужны?',
            'answer': `модульные тесты, проверяют отдельные компоненты, функции etc<br>
поддерживают качество кода, проверка компонентов, на предмет того, что они работают "как надо"<br>
упрощают рефакторинг, проще вносить изменения зная что если что-то крашится, тесты это обнаружат<br>
экономия времени на дебагинг <br>
снижение страха перед изменениями<br>
своего рода документирование<br>
улучшение архитектуры (декомпозиция интерфейса)<br>
ускорение разработки в перспективе`},
        5: {'question': 'Что такое интеграционные тесты? Зачем они нужны?',
            'answer': `тестируют взаимодействие компонентов (тут пример с щеколдой на двери)<br>
нужны чтобы отследить ошибки взаимодействия и избежать непредсказуемого поведения<br>
помогают выявить проблемы, которые могут возникнуть при интеграции новых компонентов или при внесении изменений в уже существующий код<br>
проще поддерживать целостность и работоспособность системы<br>
поддтверждение соответствия требованиям заказчика`},
        6: {'question': 'Что такое mock-тесты? Зачем они нужны?',
            'answer': `Макетные тесты, замена реальных объектов фиктивными, позволяют изолировать компоненты и избавиться от зависисимости системы от внешних факторов - АПИ или БД<br>
мок-объект - объект, которому присвоен вызов функции мок()<br><br>
from unittest.mock import Mock<br>
# Создание мока<br>
mock_db = Mock()<br>
# Использование мока в тесте<br>
def test_database_interaction():<br>
    <4s>mock_db.query.return_value = "Mock data"<br>
    <4s>result = my_function_that_interacts_with_db(mock_db)<br>
    <4s>assert result == "Mock data"<br><br>

assert - это if Утверждение == True, AssertionError вызывается только когда когда условие не выполняется<br><br>

изолируем только тестируемый компонент<br>
ускоряем тестирование за счет отсутствия запросов к внешним ресурсам<br>
моками можно тестировать "крайние" случаи и ошибочные ситуации, которые тяжело реализовать с реальными объектами<br>
моками спокойно можно тестировать взаимодействие с внешними ресурсами не боясь внести в них изменения<br><br>

assert_called_ ,,,      проверка количества, сколько раз вызывался объект`},
        7: {'question': 'Фикстуры',
            'answer': `фикстура - статические данные или объекты, которые создаются и предоставляются для тестирования<br>
фикстура - декоратор<br><br>
import pytest<br>
# Создание фикстуры<br>
@pytest.fixture<br>
def setup_data():<br>
    <4s>data = {"key": "value"}<br>
    <4s>return data<br>
# Использование фикстуры в тесте<br>
def test_something_with_fixture(setup_data):<br>
    <4s>assert setup_data["key"] == "value"<br><br>
    Моки используются для имитации поведения каких либо объектов.<br>
    Фикстуры ведут себя определенным нами образом, задаем им параметры, проверяем ведет ли себя функция ожидаемым образом.<br><br>

    Например, есть подключение к БД, можно создать фиктивный объект - моком и имитировать подключение без его фактического наличия (в примере мокал requests)<br>
    Либо вариант, есть авторизация, можно фикстурой задавать креды и проверять работоспособность.<br>
    `},
        8: {'question': 'Скоуп в тестах',
            'answer': `Локальный скоуп - каждый тест может иметь локальный скоуп в котором определены переменные и данные используемые только в рамках этого конкретного теста.<br>
Глобальный скоуп - данные и переменные доступны всем тестам в рамках определенного набора тестов.<br>
Фикстуры могут иметь разные уровни скоупа: функциональный (один тест), модульный (в пределах модуля тестов), классовый (в пределах класса тестов), глобальный (в пределах всего тестового запуска).`},
        9: {'question': 'Параметризация',
            'answer': `@pytest.mark.parametrize("input_a, input_b, expected", [(1, 2, 3),(0, 0, 0),(-1, 1, 0),])<br>
параметризация - возможность вызывать один и тот же тесткейс со всеми прописанными параметрами.<br>
уменьшает дублирование кода<br>
у пайтест удобнее параметрайз`},
        10: {'question': 'Sentry',
            'answer': `Sentry - сервис для мониторинга и отслеживания ошибок:<br>
            Что умеет:<br>
отслеживание ошибок<br>
стек вызовов и трассировка<br>
уведомления и интеграции<br>
агрегирование и анализ данных, фильтры поиска итд, удобный гуи`},
        11: {'question': 'E2E сквозное тестирование End-to-end',
            'answer': `Тестирование всего функционала, на предмет работоспособности, целостности данных и связей с другими системами.<br><br>
            Фреймворк сквозного тестирования включает в себя три части:<br>
1. Создание пользовательских функций<br>
2. Создание условий<br>
3. Создание тест-кейсов<br><br>
Подробнее:<br>
1) Перечислить все функции системы и их компоненты; перечислить входные данные, действия и выходные данные для всех функций; определить отношения между функциями;<br>
Например:<br>
Вход в систему --- Проверить статус своей заявки --- Создать заявку --- Выйти из системы.<br><br>
2) Строить условия на основании функций - проверка на каждом этапе с доп. условиями:<br>
Страница авторизации:<br>
<4s>*Неверное имя пользователя и пароль<br>
<4s>*Проверка с действительным именем пользователя и паролем<br>
<4s>*Проверка надежности пароля<br>
<4s>*Проверка сообщений об ошибках<br>
Страница заявки:<br>
<4s>Попробовать совершить запрещенные действия<br>
<4s>Зайти, пингануть ответственного через рассылку<br>
Создать тестовый сценарий:<br>
<4s>Зайти-создать заявку-выйти<br>
3) Создать несколько тест-кейсов:<br>
Создать один или несколько тест-кейсов для каждого определенного сценария.
 `},
    },
    'oop': {
        1: {'question': 'Ссылки на материалы для изучения',
            'answer': `1) <a href="${links['oop'][0]}" target="_blank">Курс по ООП</a> от Сергея Балакирева<br>
                       2) Подробное объяснение <a href="${links['oop'][1]}" target="_blank">концепций SOLID</a><br>
                       3) Подробное объяснение <a href="${links['oop'][2]}" target="_blank">концепций ООП</a>`},
        3: {'question': 'Что такое SOLID?', 'answer': `<strong>Принцип единственной ответственности (single responsibility principle) </strong>- у модуля должна быть только одна причина для изменения,
        нужно изменять и объединять модули таким образом, чтобы изменения затрагивали не более одного модуля.<br>
Паттерны: выделение класса; фасад; прокси; валидация форм; Антипаттерны: синглтон; смешение архитектурных слоёв; божественный объект;
Коротко, что позволяет: позволяет декомпозировать задачи - по одной на модуль; уменьшает количество модулей, которые нужно изменить, при изменении требований; ограничивает влияние изменений, помогая контролировать сложность системы.<br>
<br>
<strong>Открытости-закрытости (open/closed principe) </strong>- модули должны быть открыты для расширения (их функциональность может быть дополнена за счет других модулей, если изменятся требования), но закрыты для изменения
(изменение модуля не должно затрагивать модули, которые его используют). проектировать стоит так, чтобы модули приходилось менять как можно реже, а расширять функционал можно было создавая новые сущности или за счет композиции со старыми.
Паттерны: инъекции зависимостей; декоратор; наблюдатель; стратегия; абстрактная фабрика; замена прямого наследования на полиморфизм или композицию; Антипаттерны: связывание через конкретные классы, синглтон, легковес
Коротко, что позволяет: заставляет проектировать модули так, чтобы они делали только одну вещь; побуждает связывать сущности через абстракции (а не реализацию), там где могут поменяться требования; обращает внимание на
места стыка и взаимодействие сущностей; позволяет сократить количество кода, который необходимо менять, при изменении требований; делает внесение изменений безопасным и дешевым;<br>
<br>
<strong>Подстановки Барбары Лисков (Liskov substitution principle) </strong>- Функции, которые используют базовый тип, должны иметь возможность использовать подтипы базового типа не зная об этом. Классы наследники
не должны противоречить базовому классу, например наследники не должны предоставлять функционал Уже чем у базового класса,<strong> поведение наследников должно быть ожидаемым для функций, использующих базовый класс.</strong><br>
Паттерны: композиция; контрактное программирование; извлечение интерфейса, извлечение суперкласса,  Антипаттерны: неожиданное поведение интерфейса; пустая реализация
Коротко, что позволяет: помогает проектировать систему опираясь на поведение модулей; вводит правила наследования, чтобы потомки не противоречили базовому поведению; делает поведение модулей
последовательным и предсказуемым; помогает избегать дублирования, выделять общую функциональность в отдельный интерфейс; позволяет при проектировании выделять проблемные абстракции и скрытые связи между сущностями;<br>
<br>
<strong>Разделения интерфейса (interface segregation principle) </strong>- сущности не должный зависеть от интерфейсов, которые они не используют.<br>
Толстые интерфейсы необходимо разделять на более мелкие и специфические, чтобы клиенты взаимодействовали с небольшими интерфейсами и знали только методы необходимые для их работы.<br>
В итоге, нужно чтобы при изменении методов интерфейса не приходилось изменять клиента<br>
Паттерны: адаптер; выделение интерфейса; множественное наследование. Антипаттерны: грязный интерфейс; пустая реализация.
Коротко, что позволяет: бороться с наследованием или реализацией ненужной функциональности; дает возможность спроектировать модули таким образом, чтобы их затрагивали изменения только тех интерфейсов,
которые они действительно реализуют; снижает зацепление модулей; предотвращает наследование ради наследования, поощряет композицию; позволяет выявлять более высокие абстракции, и находить неочевидные связи между сущностями.<br>
<br>
<strong>Инверсии зависимостей (dependencies inversion principle) </strong>- высокоуровневые модули не должны зависеть от низкоуровневых, оба типа модулей должный зависеть от абстракций;
сами абстракции не должны зависеть от деталей реализации, детали должны зависеть от абстракций.
Паттерны: инъекция зависимостей; наблюдатель; шаблонный метод. Антипаттерны: контрол-фрик; локатор служб.
Коротко, что позволяет: вводит правила и ограничения для зависимости одних модулей от других; снижает зацепление модулей; делает тестирование модулей проще; позволяет проектировать систему таким образом, чтобы модули были заменяемы на другие;<br>
<br>
<a href="https://web-creator.ru/articles/solid" target="_blank">SOLID</a>
`},
        2: {'question': 'Концепции ООП.',
            'answer': `Основных концепций ООП 3: инкапсуляция, наследование и полиморфизм. Так же иногда отдельно
                       выделяют четвёртую концепцию - абстракция.<br><br>
                       Где я применяю каждую концепцию?<br><br>
                       Класс - шаблон для создания объектов, может содержать атрибуты и методы.<br><br>
ООП - это больше про разделение ответственности, а не про юзер, пост и тд, стоит разделять не по принципу человек, имейл, бд, а по зоне ответственности за выполняемые функции.<br><br>
<b>Абстракция</b> - введение абстрактных сущностей, чтобы обозначать принадлежность и обозначать шаблоны, а реализацией и расширением интерфейса заниматься в классах наследниках,
например Аккаунт(логин,пароль,баланс)-АккаунтВип(+дисконт)-АккаунтГест<br>
Полиморфизм - реализация полиморфного поведения объекта. Позволяет объектам разных типов использовать одинаковый интерфейс, вызывать через один метод, даже не смотря на различия в реализации.
Метод сэндмэссендж вызову для email и для sms и механизм отработает, не смотря на то, что реализация разная, ручки разные.<br>
<b>Наследование</b> - позволяет создавать новые классы на основе существующих, наследники получают атрибуты и методы родителей и могут их изменять или раширять функционал.<br>
<b>Инкапсуляция</b> - сокрытие деталей реализации и предоставление только безопасных методов для взаимодействия. Отделение данных и логики от того, чего касается пользователь. из функции, метода и тд мы светим только название.<br><br>
self - ссылка на объект, из которого этот метод был вызван.<br>
Инкапсуляция - предоставление только "безопасных" методов для использования из вне @property set get del.<br>
Наследование - копирует атрибуты и методы предка. super(), позволяет их использовать, а так же переопределять.<br>
Полиморфизм - позволяет вызывать одноименные методы разных классов даже если они отработают по разному.<br>
Абстракция - скрывает то, что под капотом, но позволяет использовать функции не зная как "именно" они работают, скрываем незначимые детали, уменьшаем сложность, повышаем эффективность.<br>
Абстрактный класс abc.ABC - базовый класс для создания абстрактных классов, содержит "пустые" методы, которые нужно будет переопределить в подклассах.<br>
abc.abstractmethod - декоратор, указывает на то, что метод является абстрактным, применяется внутри абстрактного класса, все помеченные им методы нужно переопределить в подклассе иначе класс также будет считаться абстрактным`},
        4: {'question': 'Что такое ромбовидное наследование?',
            'answer': `Ромбовидное наследование (diamond inheritance) - это специфика множественного наследования,
                       которая возникает, когда один класс наследуется от двух классов через промежуточный класс,
                       которые оба наследуют от одного и того же базового класса. Это создает структуру наследования в
                       форме ромба, где базовый класс расположен на вершине ромба, а наследующие классы - на боковых
                       сторонах.<br>
                       <br>
                       Ситуация, когда классД наследуется от двух классовB и C, которые в свою очередь унаследованы от одного общего классаА. Неясно, если обращаться к атрибуту или методу класса А, через Д, то должен ли быть использован метод из B и С.<br>
для решения есть возможность использовать метод MRO Method Resolution Order - укажет порядок поиска методов.
                       `},
        5: {'question': 'Что такое абстрактный класс?',
            'answer': `Абстрактный класс похож на интерфейс, но в отличии от интерфейса в абстрактном классе у методов
                       можно прописать реализацию. В Python в ядре языка нет реализации абстрактных классов,
                       однако с версии языка 2.6 в стандартную библиотеку добавлен модуль abc и абстрактный класс
                       можно создать путем наследования от класса abc.ABC из модуля abc и объявления абстрактных
                       методов с помощью декоратора @abstractmethod и абстрактных свойств с помощью декоратора
                       @abstractproperty.`},
        6: {'question': 'Что такое интерфейс? ',
            'answer': `Интерфейс хранит описание методов с их параметрами без реализации, т.е. интерфейс не является
                       классом и для него нельзя создать объект. В Python нет интерфейсов, но есть концепция
                       "duck typing", которая позволяет проверять объекты на наличие нужных атрибутов и методов вместо
                       проверки типов данных. Это означает, что классы могут использоваться как интерфейсы, если они
                       предоставляют необходимый функционал.`},
        7: {'question': 'duck typing',
            'answer': `Утиная типизация - концепция в программировании, где внимание в первую очередь уделяется поведению объекта, а не определению его типа.<br>
                       Тут мы будем использовать библиотеку typing, из нее брать Protocol и можно TypeVar.<br>
                       от Протокол будем наследоваться, а через тайпвар передавать значение в удобном формате<br><br>
                       Было:<br>
                       def calculate_windowed_avg(
        measurements: Union[List[TemperatureMeasurement], List[HumidityMeasurement]],
        window_size: timedelta,
        field_name: str
    ) -> Dict[datetime, float]:<br>
    window_upper_bound = measurements[0].timestamp + window_size<br>
    current_window = []<br>
    window_averages = OrderedDict()<br>
    for m in measurements:<br>
        # various calculations happen here<br>
        # based on the timestamp of each measurement<br>
        ...<br>
    return window_averages<br><br>
                       Стало:<br>
                       from typing import Protocol, TypeVar<br>
from datetime import datetime<br>
class MeasurementLike(Protocol):<br>
    timestamp: datetime<br>
M = TypeVar('M', bound=MeasurementLike)<br>
def measurement_as_timezone(measurement: M, tz: tzinfo) -> M:<br>
    measurement.timestamp = measurement.timestamp.astimezone(tz)<br>
    return measurement<br>
                        `},
        20: {'question': 'Как в Python указать модификатор private?',
            'answer': `В Python нет такого модификатора доступа, как private, как, например, в Java или C#. Вместо
                       этого в Python используется соглашение об именовании, которое гласит о том, что имя атрибута или
                       метода, начинающееся с одного символа подчеркивания, относится к категории protected и к нему можно
                       обращаться только внутри класса и его наследников, а имя атрибута или метода, начинающееся с двух
                       символов подчёркивания, относится к категории private и его можно использовать только внутри самого
                       класса. В случае с одним подчёркиванием это лишь соглашение на словах, т.е. фактически к таким
                       атрибутам и методам если захотим мы сможем без проблем обратиться, а вот в случае с двойным
                       подчёркиванием есть внутренний механизм в Python, который прячет такие атрибуты и методы, но так
                       же не на 100% - Python лишь усложняет к ним доступ - изменяет имя, по которому к ним можно обратиться.
                       Через функцию dir() можно вывести все методы и атрибуты класса и посмотреть какое имя Python присвоил
                       нашим private методам, через эти имена к ним и можно обращаться. Т.е. оба этих способа не являются
                       надёжной защитой от доступа к приватным свойствам/методам. Кстати, многие IDE подчёркивают как
                       ошибку обращение к таким атрибутам и методам, дополнительно сигнализируя программисту обратить
                       внимание что он нарушает правила.<br>
                       <br>
                       В Python есть возможность прописать внутри класса свои геттеры и сеттеры через декоратор @property:<br>
                       @property - в качестве getter<br>
                       @<атрибут>.setter - в качестве setter<br>
                       @<атрибут>.deleter - в качестве deleter<br>
                       С помощью этого механизма можно частично реализовать логику "private" доступа к атрибутам. Это
                       позволит скрыть от пользователя некоторые свойства и методы. Однако и этот способ не позволяет
                       полностью защититься от доступа за пределами класса (получить свойство и присвоить ему значение
                       можно через метод __dict__[name] = value), где name - имя свойства. Это скорее инструмент для
                       условной защиты свойств класса.<br>
                       Пример реализации:<br>
                       class MyClass:<br>
                       <4s>def __init__(self, val):<br>
                       <4s><4s>self._val = val<br>
                       <br>
                       <4s>@property<br>
                       <4s>def val(self):<br>
                       <4s><4s>print("Getting val")<br>
                       <4s><4s>return self._val<br>
                       <br>
                       <4s>@val.setter<br>
                       <4s>def val(self, value):<br>
                       <4s><4s>print("Setting val")<br>
                       <4s><4s>self._val = value<br>
                       <br>
                       <4s>@val.deleter<br>
                       <4s>def val(self):<br>
                       <4s><4s>print("Deleting val")<br>
                       <4s><4s>del self._val<br>
                       <br>
                       Однако всё же есть способ жёстко ограничить доступ к атрибутам и методам в классе - с помощью
                       библиотеки accessify. Она предоставляет декораторы @private и @protected, которые можно прописать
                       к нужному методу или атрибуту класса и тогда они получат реальный уровень доступа private или
                       protected и к ним нельзя будет обратиться извне.<br>`},
        8: {'question': 'Как проверить, что элемент является экземпляром класса в Python?',
            'answer': `isinstanse(элемент, Класс)<br>
            <br>
                        isinstance(my_element, TargetClass)`},
        9: {'question': 'Магические методы классов в Python?',
            'answer': `<b>Специальные методы, которые могут быть определены в пользовательских классах, определяют как должны вести себя объекты классов при выполнении определенных операций, таких как вызов функции, сложение и тд.<br>
                        Нужны для того чтобы реализовать свойства объектов при их взаимодействии.</b><br>
                       1) __new__  -  отвечает за фактическое создание и инициализацию объекта, в основном используется чтобы настраивать создание экземпляров класса
                        тех объектов, которые наследуются от неизменяемых типов int, str, tuple<br>
                       2) __init__  -  конструктор класса - вызывается при создании нового экземпляра класса<br>
                       3) __del__ - деструктор, вызывается автоматически сборщиком мусора, практически никогда не используется.<br>
                       4) __call__ - автоматически вызывается при вызове класса (когда мы пишем имя класса и далее
                       круглые скобки). Если определить этот метод в экземпляре класса, то он будет срабатывать каждый
                       раз при вызове экземпляра класса с круглыми скобками (такие классы называются функторами).<br>
                       5) __str__ - служит для отображения информации об объекте класса для функций print, str<br>
                       6) __getattr__(self, name) в Python - это метод специального имени (special method), который
                       вызывается в случае, если атрибут, на который происходит обращение, отсутствует в экземпляре
                       класса. Если определить в классе метод __getattr__(name), то при попытке обратиться к
                       несуществующему атрибуту будет вызван именно этот метод.<br>
                       7) __setattr__(self, key, value) - автоматически вызывается при изменении свойства key класса<br>
                       8) __delattr__(self, item) - автоматически вызывается при удалении свойства item (не важно существует оно или нет)<br>
                       9) __getattribute__(self, item) - автоматически вызывается при получении свойства класса с именем item<br>
                       10) __dict__<br>
                       11) __set_name__ (у дескрипторов)<br>
                       12) __set__ (у дескрипторов)<br>
                       13) __get__ (у дескрипторов)<br>
                       14) __repr__ - служит для отображения информации об объекте класса в режиме отладки (для разработчиков).
                       Вызывается, когда мы пишем в консоли имя экземпляра класса без каких либо функций.
                       Если в классе не определён метод __str__, то так же будет вызываться функциями print и str<br>
                       15) __len__ - вызывается при передачи экземпляра класса в функцию len()<br>
                       16) __abs__ - вызывается при передачи экземпляра класса в функцию abs()<br>
                       17) __add__ - вызывается при применении к экземпляру класса оператора сложения (справа от него).
                       Так же есть аналогичный метод __radd__, который так же вызывается при применении к экземпляру
                       класса оператора сложения, но слева от него. Ещё есть аналогичный метод __iadd__, который вызывается
                       при применении слева от экземпляра класса оператора += (если уже определён метод __add__, то
                       операция += выполнится и без __iadd__, но в таком случае мы создадим лишний экземпляр класса,
                       отдельный метод __iadd__ позволяет этого избежать)<br>
                       18) __sub__ - вызывается при применении к экземпляру класса оператора вычитания. По аналогии с
                       методом __add__ есть так же методы __rsub__ и __isub__.<br>
                       19) __mul__ - вызывается при применении к экземпляру класса оператора умножения. По аналогии с
                       методом __add__ есть так же методы __rmul__ и __imul__.<br>
                       20) __truediv__ - вызывается при применении к экземпляру класса оператора целочисленного деления.
                       По аналогии с методом __add__ есть так же методы __rtruediv__ и __itruediv__.<br>
                       21) __floordiv__ - вызывается при применении к экземпляру класса оператора деления со знаками
                       после запятой. По аналогии с методом __add__ есть так же методы __rfloordiv__ и __ifloordiv__.<br>
                       22) __mod__ - вызывается при применении к экземпляру класса оператора деления по модулю (взятие
                       остатка от деления). По аналогии с методом __add__ есть так же методы __rmod__ и __imod__.<br>
                       23) __eq__ - вызывается при применении к экземпляру класса оператора ==, т.е. при проверке на
                       равенство. Если метод не определён в классе, то по умолчанию сравнивать будет id экземпляра класса.<br>
                       24) __ne__ - вызывается при применении к экземпляру класса оператора !=, т.е. при проверке на
                       неравенство. Если метод не определён в классе, но уже определён метод __eq__, то вызовет его и
                       инвертирует результат (вернёт обратный результат).<br>
                       25) __lt__ - вызывается при применении к экземпляру класса оператора <. Если метод не определён в
                       классе, но уже определён метод __gt__, то вызовет его и инвертирует результат (вернёт обратный результат).<br>
                       26) __le__ - вызывается при применении к экземпляру класса оператора <=. Если метод не определён в
                       классе, но уже определён метод __ge__, то вызовет его и инвертирует результат (вернёт обратный результат).<br>
                       27) __gt__ - вызывается при применении к экземпляру класса оператора >. Если метод не определён в
                       классе, но уже определён метод __lt__, то вызовет его и инвертирует результат (вернёт обратный результат).<br>
                       28) __ge__ - вызывается при применении к экземпляру класса оператора >=. Если метод не определён
                       в классе, но уже определён метод __le__, то вызовет его и инвертирует результат (вернёт обратный результат).<br>
                       29) __hash__ - вызывается при вычислении хэша объекта класса.<br>
                       30) __bool__ - вызывается при проверке объекта класса на булевый тип (True/False). По умолчанию
                       любой экземпляр класса при проверке на булевый тип вернёт True. Можно самим определить метод
                       __bool__, тогда он вернёт результат нашей прописанной логики. Важно - результатом должно быть
                       значение True или False, иначе выдаст ошибку. Так же есть исключение - если в классе не определён
                       метод __bool__, но определён метод __len__, тогда при проверке на булевый тип будет вызван метод
                       __len__, причём в отличии от метода __bool__ он возвращает числовые значения, следовательно если
                       число будет 0, тогда это будет False, а любое другое число будет True.<br>
                       31) __getitem__ - вызывается при обращении к экземпляру класса по индексу. Например myObject[2],
                       где myObject это экземпляр класса. Для такого случая нужно определить метод __getitem__(self, index),
                       в который будет передан индекс и мы реализуем логику обращения к какому-либо итерируемому свойству
                       нашего класса и вернём результат.<br>
                       32) __setitem__ - вызывается при присвоении значения экземпляру класса по индексу. Например
                       myObject[2] = 5, где myObject это экземпляр класса. Для такого случая нужно определить метод
                       __setitem__(self, index, value), в который будет передан индекс и новое значение и мы реализуем
                       логику присвоения нового значения какому-либо итерируемому свойству класса.<br>
                       33) __delitem__ - вызывается при применении оператора del при обращении к экземпляру класса по
                       индексу. Например del myObject[2], где myObject это экземпляр класса. Для такого случая нужно
                       определить метод __delitem__(self, index), в который будет передан индекс и мы реализуем логику
                       удаления элемента из какого-либо итерируемого свойства класса.<br>
                       34) __iter__ - вызывается при передаче экземпляра класса в функцию iter(). Например, если у нас
                       есть объект myObject и мы реализуем цикл for item in myObject, то будет неявно вызвана функция
                       iter() и в неё будет передан объект myObject. В таком случае у объекта будет вызван метод __iter__
                       с реализованной нами логикой, а если метод не определён, то произойдёт ошибка.<br>
                       35) __next__ - вызывается при передаче объекта класса в функцию next().<br>`},
        10: {'question': 'Как получить все свойства класса в Python?',
            'answer': `Можно отфильтровать список, используя функцию inspect.ismethod из модуля inspect:<br>
                        obj = MyClass()<br>
                        properties = [attr for attr in dir(obj) if not inspect.ismethod(getattr(obj, attr))]<br>
                        <br><br>
                        Можно использовать функцию dir(), которая вернёт все свойства и методы класса, а затем
                       исключить методы. Например, так можно реализовать метод, обнуляющий все свойства в классе:<br>
                       def reset(self):<br>
                       <4s>for attr in dir(self):<br>
                       <4s><4s>if not callable(getattr(self, attr)) and not attr.startswith("__"):<br>
                       <4s><4s><4s>setattr(self, attr, None)`},
        11: {'question': 'для вставки',
             'answer': `Это методы по умолчанию, которые есть у любого класса при его создании, имена таких методов
                        начинаются и заканчиваются двойным нижним подчёркивание.`},
        12: {'question': 'Какие типы методов есть в классах Python?',
             'answer': `В классах Python есть 3 типа методов. Например:<br>
методы экземпляра принимают селф и атрибуты<br>
методы класса @classmethod принимают цлс и рабоют с атрибутами класса<br>
статические методы @staticmethod не принимают селф или цлс, но их можно передать явно<br>
<br>
                        class MyClass:<br>
                            <4s>GLOBAL_ARG = 100<br><br>

                            <4s>def __init__(self, x, y):<br>
                                <4s><4s>self.x = x<br>
                                <4s><4s>self.y = y<br><br>

                            <4s>def first_method(self, arg1, arg2):<br>
                                <4s><4s>print(arg1 * x + arg2 * y)<br>
                                <4s><4s>self.x = arg1<br>
                                <4s><4s>self.y = arg2<br><br>

                            <4s>@classmethod<br>
                            <4s>def second_method(cls, arg):<br>
                                <4s><4s>print(cls.GLOBAL_ARG * arg)<br>
                                <4s><4s>cls.GLOBAL_ARG = arg<br><br>

                            <4s>@staticmethod<br>
                            <4s>def third_method(arg1, arg2):<br>
                                <4s><4s>print(arg1 * arg2)<br><br>

                        1) first_method - это тип метода по умолчанию, который принимает в качестве обязательного
                        аргумента экземпляр класса через ключевое слово self (в неявном виде) и лишь через него
                        происходит обращение к методу. В таком методе мы можем обращаться к свойствам экземпляра класса.<br>
                        - my_instance = MyClass(1, 2)<br>
                        &nbsp;&nbsp;my_instance.first_method(3, 4) или MyClass(my_instance).first_method(3, 4), что
                        эквивалентно друг другу.<br> В данном примере выполнится код print(1 * 3 + 2 * 4) и в консоль
                        будет выведено число 11, а затем мы изменяем свойства созданного класса x и y на переданные в
                        метод два аргумента.<br><br>
                        2) second_method - тип метода самого класса, где не требуется иметь готовый экземпляр класса
                        для обращения к методу, обращение к методу идёт через обращение к самому классу. Данный тип
                        метода объявляется через декоратор @classmethod. Принимает обязательный аргумент - сам класс
                        через ключевое слово cls (в неявном виде). В таком методе мы можем обращаться к свойствам самого
                        класса, которые являются общими для всех экземпляров класса:<br>
                        - MyClass.second_method(5)<br>
                        В данном примере выполнится код print(100 * 5) и в консоль будет выведено число 500, а затем мы
                        изменяем общее свойство нашего класса GLOBAL_ARG на переданный в метод аргумент.<br><br>
                        3) third_method - статический тип метода, который не имеет обязательных аргументов. Данный тип
                        метода объявляется через декоратор @staticmethod. По сути является полным аналогом обычной функции,
                        только упакованной в класс для удобства, например для объединения функций по тематикам класса.
                        Может иметь доступ к экземпляру класса или объекту самого класса, если их передать в него в виде
                        опциональных аргументов (если заранее их объявили в методе).<br>
                        - MyClass.third_method(7, 8)<br>
                        В данном примере выполнится код print(7 * 8) и в консоль будет выведено число 56.<br>
                        Метод не умеет по умолчанию принимать экземпляр класса или объект самого класса, но их можно
                        передать явно (объявив заранее в методе как обычные аргументы) и точно так же взаимодействовать
                        с ними, изменять их. Например можно реализовать статический метод, который явно принимает
                        экземпляр класса и объект класса (остальной код класса как в первом примере):<br>
                        @staticmethod<br>
                        def third_method(arg1, arg2, arg3, cls_arg, self_arg):<br>
                            <4s>print(arg1, arg2, self_arg.x, self_arg.y, cls_arg.GLOBAL_ARG)<br>
                            <4s>self_arg.x = arg1<br>
                            <4s>self_arg.y = arg2<br>
                            <4s>cls_arg.GLOBAL_ARG = arg3<br>
                        <br>
                        my_instance = MyClass(1, 2)<br>
                        MyClass.third_method(9, 3, MyClass, my_instance)<br>
                        <br>
                        В данном примере мы создали экземпляр класса, затем вызвали статический метод и явно передали в
                        него экземпляр класса и объект самого класса  и ещё три числа. В результате выполнился код
                        print(9, 3, 1, 2, 100), а далее мы присвоили свойствам экземпляра класса и глобальному свойству
                        класса значения переданных числовых аргументов.
                        `},
        13: {'question': 'Что такое атрибуты класса в Python?',
             'answer': `Это свойства (переменные) и методы (функции) класса, которые принадлежат самому классу, а не его экземплярам, но ак же могут быть использованы его экземплярами.`},
        14: {'question': 'Как получить все атрибуты класса в Python?',
             'answer': `Можно использовать функцию dir(), которая в качестве аргумента принимает экземпляр класса и
                        возвращает всего его методы и свойства.<br>
                        <br>
                        <b>MyClass.__dir(объект класса)__</b>`},
        15: {'question': 'В чём отличие уровней доступа private и protected?',
             'answer': `private разрешает доступ только в внутри самого класса, а protected внутри класса и его
                        наследников и к нему можно обратиться без ошибки. Но они оба запрещают доступ извне к защищённому свойству/методу извне класса.`},
        16: {'question': 'Что такое дескриптор в Python?',
             'answer': `<b>Специальный класс, который определяет поведение доступа к атрибутам другого класса геттер сететтер делит = пропертис, классметодс, статисметодс.</b><br>
             <br>
                        Дескриптор в Python - это объект, который может определять, как должны работать операции доступа
                        к атрибутам класса. Он позволяет настраивать поведение чтения, записи и удаления атрибутов
                        объекта. Если у каких то свойств нашего класса должны быть одинаковые методы доступа, дескрипторы
                        позволяют сделать единый шаблон, избавляя от необходимости каждому свойству класса прописывать
                        методы доступа по отдельности, что загромождало бы код. Таким образом дескрипторы позволяют гибко
                        управлять доступом к атрибутам класса, делают код более читаемым и модульным. Например:<br>
                        class Descriptor:<br>
                        <4s>def __get__(self, instance, owner):<br>
                        <4s><4s># Логика чтения значения атрибута<br>
                        <4s><4s>pass<br>
                        <br>
                        <4s>def __set__(self, instance, value):<br>
                        <4s><4s># Логика записи значения атрибута<br>
                        <4s><4s>pass<br>
                        <br>
                        <4s>def __delete__(self, instance):<br>
                        <4s><4s># Логика удаления атрибута<br>
                        <4s><4s>pass<br>
                        <br>
                        class MyClass:<br>
                        <4s>attribute_one = Descriptor()<br>
                        <4s>attribute_two = Descriptor()<br>
                        <br>
                        В этом примере класс Descriptor является дескриптором, а класс MyClass содержит атрибут attribute_one
                        и attribute_two, которые будет обрабатываться с помощью этого дескриптора.`},
        17: {'question': 'Что такое функторы в Python?',
             'answer': `Это объекты, которые могут быть вызваны, те у них определен метод call. При вызове они выполняют определенное действие или возвращают значение.<br>
например функция или класс это функторы. Экземпляр класса так же можно сделать функтором, прописав для него call<br>
Это классы, которые можно вызвать как функцию, должен быть определен __call__ <br>
<br>
Функторы полезны в след.спенариях:<br>
1. когда нужно передать фукцию или метод в качестве аргумента другой функции<br>
2. когда нужно сохранить состояние между вызовами функции<br>
3. когда нужно добавить дополнительную логику к вызову метода или функции
<br><br>
class MyFunctor:<br>
    def __init__(self, value):<br>
        self.value = value<br>
    def __call__(self, x):<br>
        return self.value * x<br>
my_functor = MyFunctor(5)<br>
result = my_functor(3)  # Вызываем my_functor как функцию<br>
print(result)  # Выведет: 15`},
        18: {'question': 'Как в Python внутри класса обратиться к самому классу без упоминания имени?',
             'answer': `<b>Через встроенную функцию self.__class__ <br>
тут self идёт в экземпляр, а экземпляр идёт в класс</b><br>
             В Python внутри класса рекомендуется обращаться к самому классу без упоминания его имени, потому
                        что в процессе разработке название класса может измениться и придётся вносить изменения по всему
                        коду. Этого можно избежать, если обращаться к классу через self.__class__. Например если внутри
                        класса мы пишем метод, который должен возвращать новый экземпляр класса, то вместо MyClass(value)
                        можно прописать self.__class__(value) - выглядит страшнее, но это более гибкое решение, которое
                        избавляет нас от привязки к имени класса.`},
        19: {'question': 'Какие принципы SOLID можно соблюсти в Python?',
             'answer': `Принцип единственной ответственности (Single Responsibility Principle, SRP): Классы в Python должны иметь только одну причину для изменения.
             Это означает, что класс должен быть ответственным только за одну функцию или задачу. Если класс выполняет несколько разных задач, стоит разделить его на отдельные классы, каждый из которых отвечает только за одну функцию.<br><br>
Принцип открытости/закрытости (Open/Closed Principle, OCP): Код в Python должен быть открыт для расширения, но закрыт для изменения. Этого можно достичь, используя наследование и полиморфизм.
Создавайте абстрактные классы или интерфейсы, которые определяют общие методы, и разрабатывайте классы, реализующие эти интерфейсы, чтобы добавлять новую функциональность, не изменяя существующий код.<br><br>
Принцип подстановки Лисков (Liskov Substitution Principle, LSP): В Python классы-наследники должны быть полностью совместимы со своими базовыми классами. Это означает,
что методы наследников должны иметь ту же сигнатуру, что и методы базового класса, и они должны сохранять предусловия и постусловия. При использовании полиморфизма важно,
чтобы объекты классов-наследников можно было использовать везде, где ожидаются объекты базового класса.<br><br>
Принцип разделения интерфейса (Interface Segregation Principle, ISP): Клиенты не должны зависеть от интерфейсов, которые они не используют. В Python можно применять этот принцип,
создавая различные интерфейсы для разных клиентов. Если клиенты требуют только некоторые методы из общего интерфейса, можно создать интерфейсы, содержащие только те методы, которые нужны клиенту.<br><br>
Принцип инверсии зависимостей (Dependency Inversion Principle, DIP): Код в Python должен зависеть от абстракций, а не от конкретных реализаций. Это делает код более гибким и позволяет
 легко менять реализацию, не меняя зависящий от нее код. В Python можно использовать инверсию зависимостей, используя абстрактные классы или интерфейсы вместо конкретных классов.`},
    },
    'django': {
        1: {'question': 'Что нового в версиях Django 2.x/3.x/4.x?',
            'answer': `Версия 3.0 (2 дек 2019):<br>
                       - добавлена поддержка MariaDB, ASGI<br>
                       Версия 3.1 (4 авг 2020):<br>
                       - добавлена поддержка асинхронных view и middleware<br>
                       Версия 4.1 (3 авг 2022):<br>
                       - добавлен асинхронный интерфейс к ORM`},
        2: {'question': 'Что такое миграции в Django?',
            'answer': `Миграции баз данных в Django - это способ управления изменениями в структуре базы данных в процессе
                       разработки приложений. Миграции позволяют автоматически применять изменения, сделанные в коде
                       приложения, к уже существующей базе данных. В Django создание миграций начинается с команды
                        makemigrations, которая создает файлы миграций на основе моделей приложения, в эти файлы записываются
                       все изменения в структуре базы данных, которые вы внесли. Затем эти миграции применяются к базе
                       данных с помощью команды migrate. Такой подход помогает разработчикам безопасно и эффективно
                       изменять структуру базы данных, минимизируя время простоя.<br>
                       <br>
                       Механизм:<br>
                       1) Захотели изменить таблицу в базе (добавить столбцы, удалить столбцы, изменить тип полей)<br>
                       2) Вносите изменение в класс, описывающий таблицу в файле models.py<br>
                       3) Выполняете команду manage.py makemigrations, которая создаст sql-запросы к базе данных,
                       нужные для изменения структуры базы данных как вы хотите<br>
                       4) Выполняете команду manage.py migrate, которая выполнит все сгенерированные sql-запросы, либо
                       выдаст ошибку в случае конфликта<br>
                       <br>
                       Файлы миграций хранят историю изменения базы данных, используя их можно откатиться до предыдущего
                       состояния базы данных.`},
        3: {'question': 'Что такое модели в Django?', 'answer': 'django answer 3'},
        4: {'question': 'Что такое prefetch_related и select_related в Django?',
            'answer': `select_related и prefetch_related - это методы оптимизации запросов в Django ORM для связей между
                       таблицами в базе данных.<br>
                       <br>
                       select_related используется для сокращения количества SQL-запросов при доступе к связанным объектам
                       по внешним ключам, делая JOIN с предварительной выборкой связанных объектов. Удобен при работе с
                       одним-ко-многим или один-к-одному отношению.<br>
                       <br>
                       prefetch_related позволяет избежать дополнительных запросов при доступе к QuerySet'у, имеющему
                       связанные объекты в виде множества. Он работает путем выполнения двух отдельных запросов к базе
                       данных - один для исходного QuerySet'а и один для заполнения кэша со всеми связанными объектами.
                       Запрос к базе данных заполняет кэш, а затем django загружает все связанные объекты из кэша вместо
                       выполнения дополнительных запросов впоследствии. Таким образом, в отличие от select_related,
                       prefetch_related особенно полезен, когда QuerySet имеет связанные объекты в виде множества, т.е.
                       имеет связь многие-ко-многим.`},
        5: {'question': 'Что такое ленивые запросы (lazy queries) в Django?',
            'answer': `Ленивые запросы (lazy queries) в Django - это объекты QuerySet, которые не выполняются сразу, а
                       только при обращении к результату запроса. Таким образом, вместо выполнения запроса к базе данных
                       сразу после создания QuerySet'а, Django откладывает выполнение запроса до момента, когда это
                       действительно необходимо (например, при доступе к первому элементу запроса). Это позволяет избежать
                       выполнения лишних запросов в случае, когда результат запроса в итоге не будет использован.`},
        6: {'question': 'Что такое QuerySet в Django?',
            'answer': `Объект QuerySet в Django используется для описания запроса к базе данных. Когда мы присваиваем
                       переменной значение из базы данных, то фактически в переменную записывается объект QuerySet,
                       который мы описали, например my_value = MyModel.objects.filter(type='string'). Само значение
                       запишется в переменную только после того, как мы обратимся к этой переменной, т.е. выполнится
                       отложенный запрос к базе данных. Примеры вопросов с техсобесов:<br>
                       1) Сколько запросов к базе данных будет выполнено в этом коде:<br>
                       a = MyModel.objects.all()<br>
                       2) Сколько запросов к базе данных будет выполнено в этой функции?<br>
                       def test():<br>
                       <4s>MyModel.object.filter(type="a")<br>
                       <4s>MyModel.object.filter(type="b")<br>
                       <4s>c = MyModel.object.filter(type="c")<br>
                       <br>
                       На оба вопроса правильный ответ - ноль, так как мы лишь описали запросы к базе данных, выполнятся
                       они лишь когда мы обратимся к тем переменным, в которые их записали.`},
        7: {'question': 'Как в Django написать прямой запрос к базе данных (например Postgres)?',
            'answer': `import psycopg2
                       <br><br>
                       conn = psycopg2.connect(database="mydatabase", user="mydatabaseuser", password="mypassword", host="localhost", port="5432")
                       <br><br>
                       cur = conn.cursor()
                       <br><br>
                       cur.execute("SELECT * FROM mytable")
                       <br><br>
                       conn.close()`},
        8: {'question': 'Как параметры есть у полей в ORM Django?',
            'answer': `- verbose_name<br>
                       - default<br>
                       - unique (так же unique_for_date, unique_for_month, unique_for_year)<br>
                       - null<br>
                       - blank<br>
                       - db_index<br>
                       - primary_key<br>
                       - editable<br>
                       - db_column`},
        9: {'question': 'Чем поле TextField отличается от CharField в ORM Django?',
            'answer': `django answer 9`},
        10: {'question': 'Опишите принцип работы связей ForeignKey, OneToOneField и ManyToManyField в ORM Django.',
            'answer': `django answer 10`},
        11: {'question': 'Что такое сигналы Django?',
            'answer': `django answer 11`},
        12: {'question': 'Опишите структуру Django проекта - файлы, папки.',
            'answer': `django answer 12`},
        13: {'question': 'Какими недостатками обладает Django?',
            'answer': `Django монолитный, от него сложно оторвать его модули. Например Django ORM, который пронизывает
                       всю систему, из-за этого ему сложно даётся асинхронность. Так же template движок (движок шаблонов),
                       от которого с трудом можно избавиться, но вы потеряете при этом часть функциональности. Таким
                       образом Django хорош в определённых сферах применения.`},
    },
    'git': {
        1: {'question': 'В чём отличие merge от rebase?',
            'answer': `Отличие между rebase и merge в Git заключается в том, как происходит объединение изменений из
                       разных веток в одну. <br>Merge создает новый коммит, который имеет двух предков - последний коммит в
                       текущей ветке и последний коммит в объединяемой ветке. <br>Rebase же перемещает все изменения из
                       текущей ветки на вершину целевой ветки, что позволяет создать линейную историю коммитов без
                       ветвлений и точек слияния. Это полезно, если вы хотите иметь чистую, простую историю коммитов в
                       ветке, или если вы работаете над веткой, которая долгое время не была обновлена и может содержать
                       конфликты с последней версией целевой ветки.`},
        2: {'question': 'Какие команды git вы использовали в работе?',
            'answer': `-git init: Инициализация нового репозитория.<br>
-git clone: Клонирование существующего репозитория.<br>
-git add: Добавление файлов в индекс для последующего коммита.<br>
-git commit: Создание коммита с сохранением изменений в репозитории.<br>
-git push: Отправка коммитов в удаленный репозиторий.<br>
-git pull: Получение изменений из удаленного репозитория и их объединение с текущей веткой.<br>
-git branch: Управление ветками (создание, удаление, переключение).<br>
-git merge: Слияние изменений из одной ветки в другую.<br>
-git checkout: Переключение между ветками или восстановление файлов из предыдущих коммитов.<br>
-git status: Показ текущего состояния репозитория.<br>
-git config: Управление настройками Git.<br>
-git reset --hard @~1 - бэкап на шаг назад<br>
-git reflog - список изменений<br><br>

-git cherry-pick - используется для выборочного применения изменений одного камита в другой "git cherry-pick <commit_hash>"<br>
можно не камитить, а просто взять изменения выбранного камита: -git cherry-pick --no-commit<br>
черипик копирует изменения ПРОИЗВЕДЕННЫЕ выбранным камитом, т.о если у нас есть ветка Фичер, там 2 камита Ф1, Ф2, мы черипикаем Ф2, в мастер, то к последнему камит М, будет добавлена РАЗНИЦА (Ф2-Ф1)<br>
можно черепикать несколько камитов списком или перечисляя хэши.<br>
3 опции черипик:<br> - черипик аборт (есть у мёрдж) - всё отменит, как было до черипика.<br> - черипик континью (есть у мёрдж) - продолжит выполнение <br> - черипик квит - остановиться там, где мы сейчас и сбросить запомнненное состояние, на котором крашнулся (случился конфликт.)<br><br>
-git rebase и merge - объединение двух веток = Первый - переписывает историю, камиты одной ветки выстраиваются за камитами другой, Второй - мердж создает камит слияния не переписывает историю<br><br>
-git reset - отменяет изменения, возвращая указатель ветки к предыдущему камиту "git reset --hard <commit_hash>"<br>
-git revert - создает новый камит, который отменяет изменения указанного камита "git revert <commit_hash>"<br>
-git blame - используется для определения того, кто и когда внёс изменения в струка указанного файла "git blame filename"<br>
-git fetch - извлекает изменения из удаленного репозитория, но не применяет их к твоей рабочей копии "git fetch origin". фетчишь изменения, смотришь на их перечень, решаешь мерджить или нет.<br>
-git stash - сохранить изменения без камита, чтобы переключиться на другую ветку.<br>
-git squash - сжимает серию камитов в один камит, например для объединения множества незначительных изменений`},
        3: {'question': 'Что такое gitignore и зачем он нужен?',
            'answer': `Это специальный файл в репозитории GIT, в котором указываем файлы и каталоги которые не следует учитывать при камитах.<br>
Служит для: <br>- для исключения конфиденцеальной информации, например пароли или ключи апи, файлы локальных настроек.
<br>- временных и промежуточных файлов - логов, кэша.
<br>- исключения файлов создаваемых при установке зависимостей и библиотек и виртуального окружения.`},
    },
    'docker': {
        1: {'question': `Что такое Docker и Docker Compose? Зачем они нужны?`,
            'answer': `Docker - инструмент для сборки, доставки и запуска приложений в контейнерах.<br><br>
            Как деплоим?<br>
            Ясно-понятно, что сначала собираем контейнер в каталоге с приложением,
                       Заходим на сервер, клонируем репозитории "-git clone ...", настраиваем ".env" (базовые ветки для сборки последней версии), потом "-bash UpdateAll" и смотрим,<br>
                       как приложение разворачивается скрипт заходит в каждую папку исходников, выкачивает, переводит исходники на новую ветку и запускает все контейнеры из докеркомпоус.<br><br>
                       Dockerfile - содержит все необходимые инструкции, по которым запускается докер-образ.<br>
                       Docker Compose — это средство для определения и запуска приложений Docker с несколькими контейнерами.<br><br><br>
                       <a href="https://habr.com/ru/companies/slurm/articles/528206/" target="_blank">Ответы на некоторые вопросы по Докер</a>`},
        11: {'question': `В чём разница при написании Dockerfile в двух этих примерах?`,
             'answer': `1) RUN apk add --no-cache git gcc g++ libffi-dev musl-dev postgresql-client postgresql-dev
                         zlib-dev pcre pcre-dev build-base && pip install --no-cache-dir -r requirements.txt && apk del
                         git gcc g++ libffi-dev musl-dev postgresql-dev zlib-dev pcre-dev build-base<br>
                         2) RUN apk add --no-cache git gcc g++ libffi-dev musl-dev postgresql-client postgresql-dev
                         zlib-dev pcre pcre-dev build-base RUN pip install --no-cache-dir -r requirements.txt
                         RUN apk del git gcc g++ libffi-dev musl-dev postgresql-dev zlib-dev pcre-dev build-base<br><br>
             Первый Dockerfile выполняет установку требуемых зависимостей с помощью команды RUN одним сложным
                        шагом. Это делается для оптимизации работы Docker, чтобы уменьшить количество слоев образа и
                        уменьшить их размер. Второй Dockerfile разбивает установку на несколько шагов, каждый из которых
                        создает свой слой Docker. Это делается для упрощения сборки и отладки Docker-образа, так как
                        каждый слой Docker может быть переиспользован при последующих сборках.`},
        3: {'question': 'Каковы основные преимущества использования Docker по сравнению с традиционными виртуальными машинами?',
            'answer': `-Докер использует легковесные контейнеры, которые делят ядро ОС и ресурсы хост-системы (можно запускать несколько на одном хосте), а каждая ВМ требует отдельную операционную систему <br>
-Запуск и остановка контейнеров требует гораздо меньше времени чем в случае с ВМ<br>
-Изолированные контейнеры работают не зависимо друг от друга, что предотвращает конфликты между зависимостями<br>
-Докер контейнеры могут быть запущены на любой хост-системе, которая поддерживает докер<br>
-Образы можно обновлять, распространять, возможна оркестрация через кубернетис или сворм <br>
-Удобный апи и гуи`},
        4: {'question': 'Как можно оптимизировать Docker-образы, чтобы уменьшить их размер?',
            'answer': `-использовать официальные образы типо alpine, python и тд - они уже оптимизированы<br>
-использовать легковесные образы типо alpine linux<br>
-использовать меньшее количество слоёв, объединять команды RUN, использовать && (амперсанд)<br>
-чистить кэш, не копировать ненужные файлы, удалять временные файлы и зависимости<br>
-использовать общий основной слой образа и добавлять к нему незначительные дополнения<br>
-использовать dockerignore`},
        5: {'question': 'Какие команды Docker вы знаете и как они используются?',
            'answer': `-run: Запускает контейнер на основе образа. Пример: docker run -d -p 80:80 nginx.<br>
-build: Собирает Docker-образ из Dockerfile. Пример: docker build -t my_image ..<br>
-pull: Загружает Docker-образ из реестра образов. Пример: docker pull nginx.<br>
-push: Отправляет Docker-образ в реестр образов. Пример: docker push my_image.<br>
-ps: Показывает запущенные контейнеры. Пример: docker ps.<br>
-images: Показывает список скачанных и созданных образов. Пример: docker images.<br>
-exec: Запускает команду в работающем контейнере. Пример: docker exec -it my_container bash.<br>
-stop: Останавливает работающий контейнер. Пример: docker stop my_container.<br>
-start: Запускает остановленный контейнер. Пример: docker start my_container.<br>
-rm: Удаляет контейнер. Пример: docker rm my_container.<br>
-rmi: Удаляет образ. Пример: docker rmi my_image.<br>
-docker-compose up: Запускает приложение, определенное в файле docker-compose.yml. Пример: docker-compose up -d.<br>
-docker-compose down: Останавливает и удаляет приложение, определенное в файле docker-compose.yml. Пример: docker-compose down.<br>
-network: Управление Docker-сетями. Пример: docker network create my_network.<br>
-volume: Управление Docker-томами для хранения данных. Пример: docker volume create my_volume`},
        6: {'question': 'Как Docker гарантирует изоляцию приложений в контейнерах?',
            'answer': `-Использует различные ядерные технологии линукс:<br>* namespaces - разделяют системные ресурсы между процессами <br>* controlgroups - ограничивает контейнерам доступ к ресурсам цпу, памяти итд<br>
-Каждый контейнер имеют свою собственную файловую систему, которая отделена от ФС других контейнеров<br>
-Докер использует технологии контроля ресурсов ядра Линукс, для изоляции ресурсов CPU, памать, дисковое пространство<br>
-Каждый контейнер имеет свое собственное сетевое пространство и айпиадрес<br>
-Каждый контейнер запускается в своём пространстве процессов`},
        7: {'question': 'Как выполняется сетевое взаимодействие между Docker-контейнерами и между контейнером и хостовой машиной?',
            'answer': `* При запуске докер создаёт виртуальную сеть к которой могут подключаться контейнеры, каждый контейнер в этой сети получай свой собственный сетевой интерфейс и айпиадрес.<br>
* Есть возможность пробросить порты между хостовой машиной и контейнером - для взаимодействия с внешними системами, если контейнер запущен с опцией -p 8080:80, то порт 8080 на хостовой машине будет проброшен на порт 80 внутри контейнера.<br>
* Докер присваивает сетевое имя каждому контейнеру, так же в докер есть свой днс сервер, контейнеры могут общаться по сетевым именам.<br>
* Мостовые сети (для изоляции группы контейнеров) <br>*Внешние сети (общаться с интернет)<br>*Оверлэй-сети и маршрутизация (для общения контейнеров в распределенных среде).`},
        8: {'question': 'Как использовать Docker Compose для управления множеством контейнеров и их зависимостей?',
            'answer': `Создаем файл конфигурации докеркомпоус.ямл<br>
вносим параметры сети, пробросы портов и сервисы (контейнеры)<br>
docker-compouse up, scale (несколько экземпляров контейнера), start, stop, down`},
        9: {'question': 'Как обновлять и масштабировать контейнеры Docker на живом сайте без прерывания работы приложения?',
            'answer': `Можно использовать оркестрацию.<br>
Можно стратегию RollingUpdate обновлять контейнеры последовательно и трафик перенаправлять на обновленный контейнер.<br>
Можно стратегию Blue-Green деплоймент делить контейнеры на категории и на одну лить трафик, а другую обновлять и после обновления перенаправлять трафло - с помощью балансировщика нагрузки.<br>
Можно HealthCheks - compose или swarm можно определять хелсчек, когда система готова к работе и можно перенаправлять трафик`},
        10: {'question': 'Какими инструментами вы пользуетесь для мониторинга и логирования контейнеров Docker?',
            'answer': `Прометеус и Графана - красивые дашборды`},
        2: {'question': 'Как обеспечить безопасность при использовании Docker и минимизировать потенциальные уязвимости?',
            'answer': `Обновлять Docker и его компоненты: Регулярно проверяйте наличие обновлений для Docker и устанавливайте их, чтобы исправить возможные уязвимости.<br>
Запускать контейнеры с минимальными привилегиями: Используйте принцип наименьших привилегий, задавая контейнерам только необходимые разрешения.
Использовать официальные образы: При возможности предпочтительно использовать официальные образы Docker, так как они обычно поддерживаются и обновляются с большей регулярностью.
Проверять безопасность образов: Перед использованием образов важно проверять их безопасность с помощью инструментов сканирования образов на наличие уязвимостей.
Применять принципы сегментации сети: Используйте сетевые политики и механизмы контроля доступа, чтобы ограничить взаимодействие между контейнерами и хост-системой.
Мониторинг и логирование: Внедрите механизмы мониторинга и журналирования, чтобы отслеживать активность контейнеров и обнаруживать возможные инциденты безопасности.
Изменять базовые настройки на кастомные.`},
        12: {'question': 'Чем отличается под от контейнера?',
            'answer': `Под - может быть совокупностью контейнеров.<br><br>
            Это абстрактный объект Kubernetes, представляющий собой «обертку» для одного или группы контейнеров. <br>
            Контейнеры в поде запускаются и работают вместе, имеют общие сетевые ресурсы и хранилище. Kubernetes не управляет контейнерами напрямую, он собирает их в поды и работает с ими`},
    },
    'drf': {
        1: {'question': 'Что такое сериализаторы в DRF?', 'answer': 'drf answer 1'},
        2: {'question': 'Как в DRF настраивается роутинг URL?',
            'answer': `Пример создания роутеров для методов /departments и /employees в файле urls.py:<br>
                       from django.urls import include, path<br>
                       from rest_framework import routers<br>
                       from .views import DepartmentViewSet, EmployeeViewSet<br>
                       <br>
                       router = routers.DefaultRouter()<br>
                       router.register(r'departments', DepartmentViewSet)<br>
                       router.register(r'employees', EmployeeViewSet)<br>
                       <br>
                       urlpatterns = [<br>
                       <4s>path('', include(router.urls)),<br>
                       ]`},
        3: {'question': 'Как сделать разграничение прав для API метода в DRF?',
            'answer':
            `Для этого в класс-представление нужно добавить поле permission_classes = [] и в нём указать каким группам
             разрешено использовать данный API метод. Например:<br>
             permission_classes = [IsAuthenticated, IsAuthenticatedOrReadOnly]`},
        4: {'question': 'Какие уровни разграничения прав к API методам есть в DRF?',
            'answer': `- IsAuthenticated<br>
                       - IsAuthenticatedOrReadOnly<br>
                       - ?`},
        5: {'question': 'Что такое встроенные DRF фильтры?',
            'answer': `Встроенные DRF фильтры - это набор классов фильтров, предоставляемых Django REST Framework "из коробки"
                       для фильтрации queryset'ов в представлениях API. Список фильтров:<br>
                       - DjangoFilterBackend<br>
                       - SearchFilter<br>
                       - OrderingFilter<br>
                       - Pagination`},
        6: {'question': 'Как в DRF добавить свой API метод с помощью ViewSet?',
            'answer': `Для этого можно использовать декоратор @action, он позволяет добавить кастомные методы к вашему
                       ViewSet.<br>
                       1) Определите свой метод внутри класса ViewSet, добавив декоратор @action перед его определением.<br>
                       2) Укажите тип метода (например, GET, POST и т. д.) в качестве параметра detail декоратора @action.<br>
                       3) Определите URL-шаблон для вашего метода, передав шаблон в качестве параметра url_path декоратора @action.<br>
                       <br>
                       `},
        7: {'question': 'Как в DRF посмотреть все API методы?',
            'answer': `Запустить локальный сервер и в адресной строке набрать 127.0.0.1:8000/api/`},
        8: {'question': 'Что такое Generics в DRF?',
            'answer': 'drf answer 8'},
        9: {'question': 'Что такое ModelViewSet в DRF? Что он в себя включает?',
            'answer': 'drf answer 9'},
    },
    'brokers': {
        1: {'question': 'Зачем нужны брокеры сообщений?',
            'answer': `* Нужны чтобы эффективно отрабатывать большое количество асинхронных запросов<br>
* Чтобы налаживать взаимодействие между различными компонентами системы - микросервисами<br>
* Способствуют более лёгкому масштабированию систем, добавлению новых компонентов без изменения старых`},
        2: {'question': 'Как устроен RabbitMQ? Чем он удобен?',
            'answer': `AMQP (Advanced Message Queuing Protocol). написал на Erlang<br><br>
Рэбит учавствует во взаимодействии продюссера и консьюмера, организует очереди<br><br>
Эксчендж - принимает сообщения от издателя<br>
Биндинг - отвечает за роутинг сообщений по очередям<br>
Кью - очереди, хранят и отдают потребителю сообщения<br><br>
Варианты роутинга:<br>
фанаут - отправка во все очереди<br>
директ - отправка в очереди по полному совпадению роутинг кей<br>
топик - разделение между очередями по шаблону * #<br>
хедерс - отправка в связаные очереди на основе пар ключ-значение, параметры (any - частичное) (all - полное) совпадение пар ключе-значение<br>
консистент-хэшинг - плагин, успользуется когда есть несколько потенциальных очередей и нужно распределить между ними нагрузку. по весу 0 - н.<br><br>
есть связь обменников E2E<br>
push-модель доставки сообщений - тупой клиент, умный брокер.<br>
есть репликация данных`},
        3: {'question': 'Как устроен Kafka?',
            'answer': `Распределенный брокер сообщений, событий. Написан на Scala и Java.<br><br>
            Структура:<br>
Брокер - прием, хранение, передача сообщений - создаётся несколько брокеров, они объединяются в кафка-кластер.<br>
Зукипер - координатор (типо базы данных) - хранит сведения о состоянии и конфигурации кластера, а так же адресная книга.<br><br>
Среди всех брокеров выделяется кафка-контроллер - обеспечивает консистентность данных.<br><br>
Сообщения - представляют из себя пары ключ-значение, ключ не обязателен.<br><br>
Алгоритм работы:<br>
Топик, принимает входящие сообщения-события, там выстраивается "очередь", потом оттуда они распределяются в том же порядке, что поступили ФИФО. данные из топика не удаляются (до плановой очистки хранилища - удаляются сегменты целиком TTL time to live).<br>
Чтобы реализовать несколько очередей создаются несколько партиций, отдаются консьюмеру не в том порядке, в котором были отданы продюсером, а в порядке определенном партициями.<br>
Данные в брокерах хранятся в Log-файлах = по умолчанию 1гб, заполняется и замораживается, а новый создается и запись производится уже в него.<br><br>
умный клиент-тупой брокер - логика работы с сообщения на стороне клиента (сами приходят за ними), так же это о том, что брокер сам обеспечивает всю логику работы с сообщениями.
есть репликация данных, назначается лидер партиция. ПИШЕМ И ЧИТАЕМ ДАННЫЕ ТОЛЬКО ИЗ LEADER РЕПЛИКИ<br><br>
есть настройка подтверждения отправки сообщений (acks): без подтверждения; подтверждение только от лидера; подтверждение от всех ISR реплик<br><br>
есть симантика доставки: не более одного сообщения отправится; как минимум одно; каждое сообщение минимум один раз<br><br>
есть отдельный Топик для хранения офсетов, чтобы если коньюмер получил сообщения, обработал и упал, распределить на другого, но повторно не обрабатывать - ТИПО УКАЗАТЕЛЯ`},
        4: {'question': 'В чём принципиальное отличие между RabbitMQ и Kafka?',
            'answer': `Разный способ обмена сообщениями = push (rabbit) / pull (kafka) модель!<br><br>
            Модель данных:<br>
RabbitMQ: Основан на модели очередей сообщений (message queues). Принцип работы - сообщения публикуются в очереди и консьюмеры извлекают их из очереди для обработки.<br>
Kafka: Основан на модели ленты журнала (log-based). Сообщения сохраняются в логе, и консьюмеры могут читать их с позиции в этом логе.<br><br>
Уровень надежности:<br>
RabbitMQ: Поддерживает различные уровни надежности, включая режимы подтверждения доставки сообщений (acknowledgment) и транзакции.<br>
Kafka: Обычно используется с высокой надежностью благодаря сохранению данных в логе, репликации и механизмам восстановления после сбоев.<br><br>
Масштабируемость:<br>
RabbitMQ: Хорошо масштабируется вертикально, что означает, что вы можете увеличивать производительность брокера путем улучшения оборудования.<br>
Kafka: Хорошо масштабируется как вертикально, так и горизонтально. Он предназначен для обработки больших объемов сообщений и может работать в кластере из нескольких брокеров.<br><br>
Сценарии использования:<br>
RabbitMQ: Хорошо подходит для сценариев, где требуется точная доставка сообщений, а также для событийно-ориентированных архитектур.<br>
Kafka: Хорошо подходит для обработки больших потоков данных в реальном времени, таких как журналы событий, логи и потоки данных.<br><br>
Типы роутинга:<br>
RabbitMQ: Поддерживает различные типы обменников, включая прямой, тематический, "все-всем" и заголовочный роутинг.<br>
Kafka: Основан на понятии топиков, и сообщения отправляются в топики, которые можно рассматривать как категории.`},
        5: {'question': 'Паттерны работы с брокерами сообщений',
            'answer': `Transactional outbox`},
    },
    'other': {
        17: {'question': 'Python медленный, но мы строим быстрые веб-сервисы, почему так получается?',
            'answer': ``},
        2: {'question': 'Что такое REST?',
            'answer': `representational state transfer  - согласованный набор архитектурных принципов, описывает принципы организации распределенных систем (взаимодействия клиента с сервером). Разграничиваем семантику HTTP<br>
Ключевые концепции:<br>
<br>
<strong>Client-Server</strong> = отделение клиента от сервера (Клиент-серверная архитектура) - разделение на клиента и сервер, позволяет им развиваться независимо друг от друга, когда код
запросов остается на стороне клиента, а код доступа к данным на стороне сервера, так проще масштабировать серверную архитектуру, а так же переносить пользовательский интерфейс на другую платформу.<br>
<br>
<strong>Stateless</strong> = сервер не хранит информацию о состоянии клиента - каждый запрос независим и самодостаточен, должен содержать всю информацию, необходимую для ответа сервера.<br>
<br>
<strong>Uniform interface</strong> = единство интерфейса - все данные должны запрашиваться через один URL-адрес, стандартными протоколами. рест полагается на протокол http и его запросы гет, пост и тд.
это упрощает архитектуру сайта или приложения и делает взаимодействие понятнее.<br>
<br>
Опредедение ресурсов - всё в рест это ресурсы, идентифицируемые по уникальному УРЛ, ресурс - это всё что может быть именовано и представлено, например юзер, книга, заказ и тд.<br>
Управление ресурсами через представления - клиент отправляет представление, обычно в виде JSON - то как он видит измененный объект (вместо подробных инструкций: "измени эту строку, удали это...")<br>
Самодостаточные сообщения - "гет хттп 1.1 хост экзампл.ком" "хттп 1.1 200 ок комтент тайп..."<br>
Гипермедиа - отправка только тех данных, которые содержат информацию о том, что делать дальше. HTML<br>
Layered system = многоуровневость системы - сервера могут находиться на разных уровнять и должны общаться  только с соседними слоями, не зависимо от других уровней.
Сервер может иметь любое количество слоев абстракиции, по сути клиенту все равно что происходит на сервере и является ли он "конечным".<br>
Casheable = кэшируемость - для увеличения производительности, ответы сервера могут кэшироваться, что снижает количество запросов к серверу; в запросе должно быть указание,
нужно ли кэшировать данные (сохранять в спец.буфере), если указание есть, то клиент получит право обращаться к этому буферу.<br>
<br>
код по запросу - не обязательный параметр, сервер может в ответе отправить код для исполнения, например js`},
        3: {'question': 'Что такое KISS?',
            'answer': `keet it simple stupid, делай проще, не усложняй.<br>
избегай избыточной сложности в разработке, чтобы потом твой код был понятен, легко поддерживался,<br>
избегать добавления избыточного кода или функциональности<br>
декомпозиция сложных задач на более простые<br>
простой код проще тестировать<br>
если нужен метод для простого вычисления, не наворачивать кучу слоёв абстракций, интерфейсов. `},
        4: {'question': 'Что такое DRY?',
            'answer': `dont repeat yourself - не повторяйся, не дублируй код, таблицы и тд. переиспользуй код в функции или модули, соблюдение единого источника правды.`},
        5: {'question': 'Что такое вебсокеты?',
            'answer': `библиотека websockets / вэбсокет - технология, позволяющая устанавливать двунаправленную связь между клиентом и сервером через одно соединение;<br>
             постоянное соединение, не разрывается после отправки\получения данных,<br>
             двунаправленное соединение (дуплексное), низкая задержка, кроссплатформенность, отправляет заголовок только один раз<br>
<br>
HTTP однонаправленное соединение, каждый раз открывается новое соединение при запросе и закрывается после запроса, есть задержка - из-за создания соединений. сетевая и серверная нагрузка - выше<br>
<br>
лучше применять в:<br>
торговых приложениях - маркетплейсах, биржах, чатах на сайтах, пуш-уведомлениях, игровых приложениях, соц.сетях, связи устройства - интернет вещей.`},
        7: {'question': 'Парсинг URL. Запрос-Ответ. Клиент-Серверная архитектура.',
            'answer': `1. парсинг URL, проверка scheme (скеме - схема) протокола http или https<br>
всегда сначала идёт в кэш ОС и кэш браузера<br>
2.1 если http: браузер запрашивает айпи у dns сервера; установка tcp соединения 80 порт; отправка запроса; обработка запроса сервером; получение и обработка ответа клиентом; рендеринг<br>
2.2 если https: dns, установка соединения 443 порт, рукопожатие, запрос, ответ, рендеринг<br>
основные отличия: рукопожатие ssl/tls - установка шифрованного соединения и обмена ключами шифрования; шифрование - все данные шифруются; аутентификация - сервер предоставляет цифровой сертификат, браузер проверяет его действительность; интегрируемость<br><br>
"Запрос - Ответ" - Взаимодействие клиента и сервера обычно осуществляется по этому принципу.<br>
1. установка соединения<br>
2. запрос - передача ЗАГОЛОВКОВ: тип контента, ожидания по кешированию, идентификационные данные и другие метаданные; ПАРАМЕТРОВ; ТЕЛО; АУТЕНТИФИКАЦИОННЫЕ данные<br>
3. обработка запроса сервером в соответствии с логикой приложения: например чтение или запись в БД, обработка запроса, подготовка ответа<br>
4. ответ, содержащий запрошенные данные или об успешном выполнении операции<br>
5. завершение соединения<br><br>
Важно выделить ряд ключевых аспектов:<br>
1. использование библиотек для создания сервера, апи<br>
2. взаиможействие с сервером, например http через requests или вебсокеты через websocets<br>
3. обработка данных сервером, работа с БД через sqlalchemy или анализ данных через pandas<br>
4. масштабирование системы, например в контексте увеличения числа запросов через использование asyncio<br><br><br>
Формат запроса:<br>
СТАРТОВАЯ СТРОКА: МЕТОД; ЦЕЛЬ ЗАПРОСА (URL); ВЕРСИЯ ПРОТОКОЛА. <br>
ЗАГОЛОВКИ ЗАПРОСА: ХОСТ ЮЗЕРАГЕНТ РЕФЕР АКСЕПТ КУКИ АВТОРИЗАШН<br><br>
GET / HTTP/1.1<br>
Host: www.example.com<br><br>
Формат ответа:<br>
СТРОКА СОСТОЯНИЯ: ВЕРСИЯ ПРОТОКОЛА; КОД ОТВЕТА; ПОЯСНЕНИЕ<br>
ЗАГОЛОВКИ ОТВЕТА; ТЕЛО ОТВЕТА<br><br>
HTTP/1.1 200 OK<br>
Server: ngnix, Set-cookie, www-authenticate`},
        6: {'question': 'CORS', 'answer': `CORS - междоменное взаимодействие ресурсов. важная часть системы безопасности, которую использует браузер для ограничения вэбстраниц во взаимодействии с ресурсами.<br>
Реализует "режим одного окна", определяя какой домен имеет доступ к ресурсам, расположенным на вэбстранице.<br>
<br>
Например в фастапи добавляем список ориджинс, содержащий список ресурсов, которые будут иметь доступ к странице (localhost:порт). создание корсМидлвеар, передаем туда разрешенные заголовки методы и тд (allow_headers, allow_methods).<br>
Достигается путём добавления соответствующих заголовков к ответам сервера.<br>
Примеры типичных заголовков CORS:<br>
Access-Control-Allow-Origin: Определяет, какие домены имеют доступ к ресурсам.<br>
Access-Control-Allow-Methods: Определяет, какие HTTP-методы разрешены для запросов к ресурсам.<br>
Access-Control-Allow-Headers: Определяет, какие заголовки HTTP разрешены в запросах.`},
        8: {'question': 'DNS; IP; URI',
            'answer': `<b>DNS - domain name system</b> - позволяет использовать человеко-читаемые имена ресурсов вместо IP адресов; временно кэшировать результаты предыдущих запросов - снижая нагрузку на сеть;<br><br>
При запросе клиента, если данных нет в кэше, то запрашиваем инфу у resolver'a - распознающий днс сервер (обычно находится у нашего интернет провайдера, либо можно его поменять и использовать 8888 или 1111)<br>
- он так же смотрит у себя в кэше, если не нашёл, то шлёт запрос к корневому ROOT серверу, он говорит к какому серверу нам обратиться,<br> дальше TLD сервер - top level domain (com, ru, net, org) == есть gTLD (generic TLD
- не привязаны к стране edu, com, ai) и есть ccTLD (country code TLD - привязаны к стране ru, us, uk),<br> дальше запрос идёт к серверу Авторитативных имён. <br>Теперь резолвер отдаст клиенту айпи и запишет адрес в кэш.<br><br>
Три типа запросов: Рекурсивный (дай айпи), Итеративный (дай айпи или авторитативный днс), Обратный (какое доменное имя у такого-то айпи)<br><br><br>
<b>IP - адрес любого девайса в сети</b>, необходим для того, чтобы они могли общаться между собой, <br>айпи существует нескольких версий, например в4 (32 бита) - в десятичной системе  и разделены точками (4.3 млрд адресов) либо в6 (128 бит) -
в шестнадцатиричной системе, разделены двоеточием (10 в 28 степени адресов = 79 октилионов возможных адресов)<br>
Классификация:<br>
-есть статические (у серверов, чтобы мы знали где их искать) и динамические (даётся на время, чтобы сервер знал куда отвечать)<br>
-есть внутренний (даёт провайдер, с ним мы находимся внутри локальной сети) и внешний (даёт провайдер, для выхода в сеть), в итоге, можно выходить в сеть с одинаковыми айпи, благодаря тому, что провайдер присваивает "порт" - уникальное значение после двоеточия айпи.<br><br>
<b>URI - Uniform Resourse Id.</b> - унифицированный(приведенный) идентификатор ресурса<br>
https://pesik@website.com:5772/kittens/meow?color=black#today<br>
(scheme) : (userinfo) @ (host) : (port) (path) ? (query) # (fragment)<br><br>
<b>URL - Uniform Resourse Locator</b> - указатель ресурса. URL = всегда URI, URI может быть URL, а может им не быть<br>
<b>URN - Uniform Resourse Name </b>- унифицированное имя ресурса. удовлетворяет Persistance<br><br>
Как понял: URI - это всё что есть в строке ввода адреса включая схему и параметры, URL - от начала, до параметров (квери), URN - се кроме схемы (https например).`},
        9: {'question': 'HTTP и HTTPs - общее представление о том как работает и в чем разница',
            'answer': `HyperText Transfer Protocol - протокол передачи гипертекста, документов, содержащих ссылки на другие документы<br>
https - расширение для http, которое делает его безопасным, при установке соединения клиент и сервер "договоравиются" о том, что они будут использовать временный ключ и шифровать данные (сеансовый ключ).<br><br>
Типы шифрования:<br>
Используется симметричное (открытый ключ - умеет только зашифровывать) и ассиметричное шифрование (открытый и закрытый ключи).<br><br>
Клиент отправляет запрос, сервер отправляет открытый ключ, клиент формирует сеансовый ключ, зашифровывает его и отправляет серверу, сервер расшифровывает сеансовый ключ и отправляет ответ, что соединение установлено.<br><br>
80 и 443 порты, S - secure = соединение безопасно, по нему можно передавать личные данные!`},
        1: {'question': 'Уровни OSI',
             'answer': `1. Физический уровень - Уровень проводов, Ethernet<br>
2. Канальный уровень - мак адреса и полезные данные<br>
3. Сетевой уровень - маршрутизация, айпи, пакеты<br>
4. Транспортный уровень - передача данных по сети TCP и UDP<br>
5. Сеансовый уровень - управление сессиями<br>
6. Уровень представления - кодирование, сжатие<br>
7. Уровень приложений - протоколы`},
        10: {'question': 'TLS/SSL принцип работы. Что такое сертификаты и как их получают',
            'answer': `Используют криптографические протоколы, для шифрования передаваемых данных, для обеспечения: конфиденциальности, целостности и аутентификации.<br>
Secure Sockets Layer - был разработан в 199х(1995) netscape, потом был заменен Transport Layer Security<br>
SSL использует коды аутентификации сообщения MAC, а TLS использует шифрование; в TLS на 1 пакет приходится 1 запись в SSL может несколько; в TLS доп.включены функции сжатия и прокладки;
TLS поддерживает различные наборы шифров, а SSL только один набор PFS использующий 1024битный ключ RSA<br><br>
Рукопожатие:<br>
1. Браузер или сервер пытается подключиться к веб-серверу, браузер запрашивает идентификацию у вэб-сервера<br>
2. Вэб-сервер отправляет копию ssl сертификата<br>
3. Браузер или сервер проверяет является ли сертификат доверенным и сообщает о этом серверу<br>
4. Затем сервер открывает сеанс зашифрованный ssl<br><br>
Сертификаты бывают разных типов, в адресной строке "замок" отображается только у Сертификата с расширенной проверкой (процесс стандартизированной проверки подлинности и подтверждение исключительных прав на домен)<br>
Сертификаты выдают Центры сертификации, сертификат имеет ограниченный срок действия.<br>
Нажав на "замок" можно узнать информацию о выданном сертификате`},
        11: {'question': 'Методы запросов и Коды ответов',
             'answer': `GET - запрашивает представление ресурса<br>
POST - отправляет объект в указанный ресурс, что чаще всего приводит к изменению состояния<br>
PUT - обновление или создание ресурса на сервере<br>
DELETE - удаляет ресурс<br>
PATCH - частичное изменение ресурса - !идемпотентный!<br>
CONNECT - устанавливает тунель к серверу, указанному целевым <br>
HEAD - запрашивает ответ идентичный ГЕТ, но без тела ответа<br>
OPTIONS - запрос информации о возможностях ресурса, в том числе о допустимых к использованию на сервере методах<br>
TRACE - проверка обратной связи сообщения на пути к ресурсу<br><br>
1хх - носят информативный характер, не влияют на отработку запроса<br>
2хх - возвращаются в случае успешной обработки запроса<br>
3хх - если серверу нужно перенаправить клиента - редирект<br>
4хх - ошибка на стороне клиента, направлен некорректный запрос, например запрошен ресурс к которому нет доступа или использован неподдерживаемый метод<br>
5хх - ошибка на стороне сервера`},
        12: {'question': 'Разница между аутентификацией и авторизацией',
             'answer': `идентификация - ты кто? система определяет "существует" данный пользователь в системе или нет, идентификатор любой: логин, телефон, почта итд<br><br>
аутентификация - докажи что ты то, за кого себя выдаешь!? процесс проверки подлинности пользователя, путем проверки данных предоставленных пользователем, таких как пароль или пинкод<br><br>
авторизация - процесс предоставления "прав" конкретному пользователю, на доступ к какому либо функционалу или действиям`},
        13: {'question': 'JWT - JSON Web Token',
             'answer': `<b>JWT - JSON Web Token </b>- простой и безопасный способ передачи информации между клиентом и сервером.<br>
<b>"зашифрованное сообщение, расшифровать которое может только получатель"</b><br><br>
Структура = три части, разделенные точкой "."<br>
1. Заголовок. Содержит метаданные о токене и используемом криптографическом алгоритме. Обычно это HMAC SHA256 или RSA {"alg": "HMAC "\n "type": "JWT"}.<br>
2. Пэйлоад, полезная нагрузка или "Утверждения". Данные которые содержит токен фактически хранятся здесь, например информацию о пользователе или дополнительные метаданные.<br>
3. Подпись. Криптографически защищенное доказательство (proof) подтверждающее отправителя и то, что сообщение не было изменено во время передачи.<br><br>
Процедура создания JWT:<br>
Клиент выполняет вход, используя креды, отправляя запрос на сервер<br>
Сервер проверяет креды, если они валидны, генерирует токен и отправлет клиенту<br>
Клиент сохраняет JWT, обычно в локальном хранилище и включает токен в заголовок каждого последующего HTTP запроса<br>
Сервер, получая эти запросы, проверяет JWT  и если он действителен, то клиент аутентифицирован и авторизован.<br><br>
Конкретно взятый токен может являться частью уже зашифрованной структуры.<br>
Сериализация производится с использованием алгоритма base64url`},
        14: {'question': 'X-CSRF токены и сессии. CSRF-атака',
             'answer': `В общем смысле токен - электронный ключ, позволяющий идентифицировать пользователя или конкретную сессию для безопасной передачи информации.<br><br>
CSRF-атака - совершение мошенником запроса к целевому сайту от имени авторизованного пользователя (сначала создается поддельная страница, например страница оплаты,
пользователь переходит на нее с другой страницы, совершает оплату на поддельной странице и данные и средства уходят вместо оригинального сервера на сервер к мошеннику)
CSRF токен - способ защитить сайт от CSRF мошенников.<br><br>
Защищать стоит методы "меняющие состояние на сервере" POST PATCH DELETE PUT<br><br>
При создании токена стоит учитывать несколько параметров:<br> -нахождение в скрытом параметре (запроса?);<br> -создание с помощью генератора псевдослучайных чисел,<br> -ограниченное время жизни (одна сессия); <br>
-уникальность для каждой транзакции; <br>-невозможность переиспользовать; <br>-устойчивый к подбору размер (в битах)<br><br>
Типы токенов:<br>
Synchronizer Tokens или Anti-CSRF (Statefull) - в этом случае инициатором ключа является сервер. Исходная шифровка хранится на нём.
При обращении браузера к серверу и предъявлению ему ключа, браузер сравнивает ключ. (если произойдет утечка токена, то злоумышленник сможет произвести CSRF-атаку на любой запрос и достаточно долго).<br>
Double Submit Cookie (Stateless) - в этом случае шифровка нигде не хранится. Когда клиент впервые обращается к серверу, сервер отправляет токен в двух формах - через куки и в одном из параметров ответа.
В дальнейшем при обращениях, сервер дважды проверяет правильность токена (тк поддомены могут читать куки основного домена, то нужно устанавливать куки на свой домен явно).<br>
Encrypted Token (Stateless) - зашифровывается часть сообщения. При первом обращении серверу передается информация о пользователе, она зашифровывается (timestamp и идентификатор пользователя) и в одном из параметров ответа возвращается ключ.`},
        15: {'question': 'OAuth 2.0',
             'answer': `OpenID служит для аутентификации, а OAuth для авторизации.<br><br>
Типы ролей:<br>
Владелец (пользователь) - авторизует клиентское приложение на доступ к своему аккаунту.<br>
Сервер ресурсов и API - здесь располагаются данные пользовательских аккаунтов, а так же бизнес-логика авторизации, отвечающая за выдачу новых OAuth токенов и проверку их валидности при обращении клиентских приложений к ресурсам.<br>
Клиентское приложение - собственно сервис, которому пользователь делегирует права доступа на сервере ресурсов, пользователь авторизуется, а API проверяет подлинность, посредством получения ключа-токена.<br><br>
Допустим мы хотим зайти на сайт www.xyz111.com и авторизоваться через google:<br><br>
Клиент запрашивает у конечного пользователя подтверждение авторизации на Сервере авторизации (google), <br>после авторизации сервер авторизации выдает клиенту грант авторизации,
<br>далее Клиент запрашивает у сервера токен доступа, при этом передает некоторую пользовательскую информацию и грант авторизации от пользователя,
<br>далее, если подлинность подтверждена и разрешение на авторизацию действительно, то сервер авторизации выдаёт токен доступа,
<br>клиент использует токен для аутентификации на сервере авторизации, клиент получает доступ к необходимым ресурсам (аккаунт google) и создаёт на их основе учетную запись. <br><br>
В протоколе описано несколько вариантов, подходящих для различных ситуаций: <br>*авторизация для приложений, имеющих серверную часть (чаще всего сайты и вэб-приложения)
<br>*авторизация полностью клиентских приложений (мобильные и десктоп) <br>*авторизация по логину и паролю <br>*восстановление предыдущей авторизации`},
        16: {'question': 'YAGNI',
            'answer': `You Aren't Gonna Need it - тебе это не понадобится<br><br>
            Не пиши код, если он тебе возможно не понадобится, не пиши код, если думаешь, что он МОЖЕТ БЫТЬ потребуется в будущем.<br>
            Принцип полезен при рефакторинге! Стоит смело удалять неиспользуемые куски кода, если они потребуются, то можно их воскресить из гит-репозитория.`},
    },
    'linux': {
        1: {'question': 'Какие основные команды есть в Linux?',
            'answer': `ls: Показать содержимое текущего каталога.<br>
cd: Изменить текущий каталог.<br>
pwd: Вывести текущий рабочий каталог.<br>
mkdir: Создать новый каталог.<br>
<b>rm: Удалить файл или каталог.</b><br>
cp: Копировать файлы и каталоги.<br>
mv: Переместить или переименовать файлы и каталоги.<br>
touch: Создать новый файл.<br>
cat: Вывести содержимое файла в терминал.<br>
more или less: Постранично просматривать текстовые файлы.<br>
head и tail: Показать начало и конец файла соответственно.<br>
grep: Искать текст в файлах с использованием регулярных выражений.<br>
find: Поиск файлов и каталогов.<br>
<b>ps: Показать запущенные процессы.</b><br>
<b>top: Показать активные процессы в реальном времени.</b><br>
<b>kill: Завершить процесс.</b><br>
sudo: Выполнить команду с правами суперпользователя.<br>
chmod: Изменить права доступа к файлу.<br>
chown: Изменить владельца файла.<br>
df: Показать информацию о дисковом пространстве.<br>
du: Показать размеры файлов и каталогов.<br>
tar: Создать архив или извлечь файлы из архива.<br>
wget или curl: Загрузить файлы из интернета.<br>
ssh: Подключиться к удаленному серверу через SSH.<br>
ping: Проверить доступность хоста в сети.`},
        2: {'question': `Если в оперативной памяти 6 гигабайт, а процесс занимает 4 гигабайта и мы делаем форк процесса,
                         то что произойдёт?`,
            'answer': `форк создаст копию процесса, который так же будет занимать 4 гб, но физически будет использовать ту же оперативную память, что и родительский процесс. но во первых он не начнет выпивать всю эту память на старте, во вторых<br>
будет использоваться подкачка, что замедлит работу системы, в некоторых случаях система может начать вытеснять данные на диск, что еще сильнее замедлит работу системы`},
        3: {'question': 'Как посмотреть все процессы?',
            'answer': `ps: Эта команда покажет вам список процессов, запущенных в текущей оболочке.<br>
ps -e: Показывает все процессы в системе.<br>
ps -ef: Показывает полный список процессов с деталями, включая идентификаторы пользователей.<br>
ps aux: Показывает дополнительную информацию о процессах, такую как использование ресурсов.<br>
ps -aux | grep <имя_процесса>: Позволяет вам найти конкретный процесс по его имени.<br>
top: Запускает интерактивный монитор процессов, показывая информацию о них в реальном времени.<br>
htop: Альтернатива команде top с более дружественным интерфейсом.`},
    },
    'system-design': {
        1: {'question': `Что такое монолит и микросервисы?Плюсы и минусы.`,
            'answer': `Монолит - всё приложение интегрируется в одном месте, все компоненты в кучу - например  бд, пользовательский интерфейс, бизнеслогика и тд взаимодействую между собой напрямую.<br>
            <br>
Микросервисы - архитектурный подход, в котором приложение разбивается на маленькие, автономные, независимые компоненты, каждый из которых отвечает за определенную функциональность.<br>
Связаны через REST API или gRPC (использует бинарный формат Protobuf) или через Мессаджинг (RabbitMQ, ZeroMQ, ActiveMQ и Kafka).<br>
Выбор схемы - поиск ответов на вопросы: Нужен брокер или нет? Нужно подтверждение доставки или нет? Запись на диск?
<br><br>
масштабируя монолит нужно поднимать весь тяжелый сервис, а отдельный микросервис же легче.<br>
в микросервисной архитектуре мы получаем низкое связывание (coupling) и высокую степень сцепления компонентов(cohecion). Делает систему более гибкой, позволяет проще заменять компоненты.
<br><br>
сетевую шину или сокеты-вэбсокеты, сетевые вызовы...`},
        2: {'question': 'Какие паттерны программирования вы знаете?',
        'answer': `Паттерн - шаблон, обобщенная конструкция, который может быть применен для решения или предотвращения типовых проблем.<br>
        <b>Стратегия</b> - применяю, чтобы не городить / убрать кучу IFов из функций, особенно если они динамически меняются, их то 3 то 5 итд. <br>Например, есть несколько функций с разным назначением: сумма, вычитание, умножение и тд,
        мы создаем action mapper - словарь, в котором key - название операции, которое приходит из переменной например, а value - соответствующая функция - не вызов, а именно ФУНКЦИЯ.<br>
        a, b, operation_1 = 3, 5, "add"<br>
        print(action_mapper[operation_1](a, b))<br>
        - Определяет семейство алгоритмов, инкапсулирует каждый из них и обеспечивает их взаимозаменяемость.
        В родительском классе есть метод set_strategy он "устанавливает" выбранный метод, например сортировка, пузырьком или обратная, те же функции - только через классы<br><br>
        <b>Декоратор</b> - реализация функции, которая принимает на вход объект, ВЫЗЫВАЕМЫЙ объект, который является callable объектом и возвращается функцию, внутри которой мы будем вызывать колабл объект.<br>
        Можно навешивать декоратор, через собачку, а можно присваивать переменным и передавать аргументы - чтобы можно было использовать исходные функции.<br>
        - Позволяет добавлять новый функционал объектам без изменения структуры класса (например навернуть скидку или описание на класс продукт в интернет магазине)<br><br>
        <b>Адаптер</b> - для преобразования интерфейса одного класса к интерфейсу другого класса, который ожидается клиентом, такой подход позволяет объектам с несовместимыми интерфейсами работать вместе.<br>
        Тут мы создаём класс Адаптер, наследуем его от класса с новым интерфейсом, переопределяем в нём метод нового интерфейса и приводим его поведение к поведению старого интерфейса.<br>
        # old - str<br>
# new - int<br>
class Old:<br>
    <4s>def get(self):<br>
        <4s><4s>return "12345"<br>
class New:<br>
    <4s>def get_int(self):<br>
        <4s><4s>return 678<br>
class Adapter(New):<br>
    <4s>def get(self):<br>
        <4s><4s>return str(self.get_int())<br>
def main(obj):<br>
    <4s>print('Результат: ' + obj.get())<br>
if __name__ == '__main__':<br>
    <4s>obj = Adapter()<br>
    <4s>main(obj)<br><br>
    <b>Фасад</b> - если нам нужно выполнять одно комплексное действие, которое дергает много методов, то стоит использовать Фасад, объединив все методы в один класс и определить функцию,
    которая стартует выполнение всех нужных методов - вместо многократного использования их по отдельности.<br>
    Учебный пример, так объяснял джуну - Предположим что у нас есть несколько функций, например формирование отчета (выполнить 5 раз), выполнить по нему расчеты (10 запусков), рассылка уведомлений (30 запусков),
    вместо последовательной реализации каждого или запуска в цикле (range 5, 10, 30) - мы создадим класс Facade, в конструкторе создадим объекты необходимых классов и создадим одну функцию, в которой реализуем запуск всего "проекта",
    а дальше клиент или мы будем использовать только одну эту функцию экземпляра.<br>
class ...<br>
class ...<br>
class Messaging:<br>
    <4s>def get_msg(self):<br>
        <4s><4s>print('message to...')<br>
class Facade:<br>
    <4s>def __init__(self):<br>
        <4s><4s>self....<br>
        <4s><4s>self....<br>
        <4s><4s>self.messaging = Messaging()<br>
    <4s>def start_project(self):<br>
        <4s><4s>for i in range(5):<br>
            <4s><4s><4s>self.messaging.get_msg()<br>
        <4s><4s>...<br>
facade = Facade()<br>
facade.start_project()<br><br>
<b>Репозиторий</b> - позволяет абстрагировать способ взаимодействия и хранения данных от логики приложения.<br>
Примерно такой же слой абстракции как ОРМ, чтобы не прописывать запросы непосредственно в ручках. Создается класс, в котором реализуются методы гет, сэйв, дэлит и тд, которые потом вызываются в ручках.
<br><br>
<b>Итератор</b> - собственные итераторы пишут, чтобы более эффективно использовать ресурсы памяти в случаях: ленивой загрузки из БД, ленивых вычислений, чтения из сокета, чтения из файла.<br>
        Чтобы по экземплярам класса можно было итерироваться, нужно переопределить дандерметод __iter__, чтобы он возвращал любой итератор, в классе нужно указывать, что итер возвращает сам себя, т.е. self<br>
        def __iter__(self):<br>
        <4s>return self<br><br>
        <br><br>Обсервер - позволяет следить за состоянием объектов и реагировать на его изменение (онлайн торговля - нотификация об изменении цен товаров)<br>
Прототип - Позволяет создавать новые объекты, копируя (клонируя) существующие, избегая сложностей их создания. Клонированные объекты потом можем изменять/модифицировать.<br>
Синглтон - гарантирует что в системе будет только один экземпляр этого класса и предоставляет глобальную точку доступа к нему (конфигурационный файл, менеджер ресурсов)<br>
Фабричный метод - (отделяет создание объектов от их использования) - предоставляет интерфейс для создания объекта, но предоставляет экземплярам доступ выбирать класс создаваемого объекта - позволяет делегировать ответственность за создание экземпляров подклассам<br>
Строитель - для сложных объектов, позволяет отделить логику конструирования от логики представления, позволяет создавать разные представления объектов.<br>
Состояние -  Позволяет объекту изменять свое поведение при изменении его внутреннего состояния. (автомат по продаже напитков: состояния есть монета нет монет, наливаю жижу...
Создаем классы "автомат" (у него метод set_state) и "состояние" реализуем пустые методы, наследуемся от него, переопределяем методы соответственно состоянию и вместо кучи проверок используем методы соответственно состоянию.<br>
Цепочка обязанностей - Позволяет передавать запросы последовательно по цепочке обработчиков, пока кто-то из них не выполнит запрос. Базовый класс с методом set_successor и handle_request, экземплярыТе же проверки if только в разных классах %2 != 0, %2 == 0 ...<br>
Команда - Инкапсулирует запрос как объект, позволяя разделить клиентов с запросами, организовать отмену операций и поддерживать разные типы операций.`
        },
        3: {'question': 'DDD - Domain driven design', 'answer': `domain driven design (предметно ориентированное программирование) - перечень соглашений по проектированию
         архитектуры приложения (типо чистая архитектура, луковая архитектура) с целью приведения бизнеса и разрабов к разговору на одном языке (Ubiquitous Language) <br>
         чтобы оперировать одиними и всем понятными терминами.<br><br>
В основе лежит Bounded Context - разграничение контекста<br><br>
Entity = сущность - фундаментальный составной элемент при построении какого-либо контекста. У него всегда есть идентификатор, можно сравнивать между собой (идентичность, референсуальность-объекты технически ссылаются на один участок памяти, структуральное-сравнение атрибутов и их значений).
например объект Product, содержит id, price, timestamp, client и тд<br><br>
Value object = то из чего состоят атрибуты Entity, нет идентификатора - сравнение на основании структуры, иммутабелен.
например price = (состоит из) value, currency.<br><br>
Aggregate root - объединяет всё это воедино и позволяет "управлять", тк все остальные элементы ВЛОЖЕНЫ в него.`},
        4: {'question': 'Jenkins + Kubernetes', 'answer': `<b>Jenkins - CI сервер.</b> вроде схож с гитлаб. Есть Мастер и Слэйвы.<br>
устанавливаем дженкинс, <br>заходим в браузере на локалхост:8080, <br>по умолчанию он на этом порту, <br>логинимся, есть команды для поиска пароля, <br>устанавливаем suggested рекомендуемые плагины, <br>
создаем админа сервера, <br>создаем задачу (джобу), <br>настраиваем триггеры, как автосборка или ручная итд, <br>можно смотреть информацию о статусах сборок.<br><br>
<b>Kubernetes - для работы с контейнерами.</b><br>
Это система оркестрации контейнеров промышленного уровня, позволяет разворачивать множество контейнеров на большом количестве машин и предоставляет из коробки много фич, <br>
например поэтапная выкатывание новых релизов и горизонтальное масштабирование под нагрузкой. Кубер вводит ряд абстракций, таких как Под и Сервис и даёт инструменты для построения сложных систем на их основе.<br><br>
Используем для:<br> автоматизации развертывания, <br>масштабирования и управления приложениями, <br>помогает сервису быть ВСЕГДА доступными,
восстанавливаться, обновляться, распределять сетевой трафик, <br>работать с конфиденциальной информацией (пароли, ООф2.0 токены и ssh).<br><br>
Структура:<br>
Есть кластеры, в кластере есть ноды (мастер (хранит требуемое состояние, расписание и логи) и воркеры (на них поднимаются поды, то поднимаются, то останавливаются в зависимости от нагрузки,
у них есть айпиадреса, айпи объединяются в группы, чтобы можно было присваивать группам постоянные айпи))<br><br>
кубер занимается:<br> * оркестрацией хранилища,<br> * конфигурация описана в декларативном стиле (состояние которое я хочу видеть, а не последовательность инструкций или действий), <br>* распределением нагрузки, <br>* разбирается с упавшими нодами<br><br>
Алгоритм из примера*:<br>brew install kubectl<br>brew install minikube<br>minikube start<br>git clone git@github.com:Saluev/habr-app-demo.git<br>cd habr-app-demo<br>git checkout feature/k8s<br>Команда для создания Пода "kubectl apply"<br>
Настраиваем yaml файл и запускаем под по указану в нём синтаксису (kubectl apply -f path/to/filename.yaml)
Для сборки Докер-образов: переходим в репозиторий, переключаемся в нужную ветку и собираем через "docker build"<br>docker build --target backend -t habr-app-demo/backend:latest backend<br>
docker build --target worker -t habr-app-demo/worker:latest backend<br>docker build -t habr-app-demo/frontend:latest frontend<br>Если бы был продакшн с хранилищем под названием habr-app-demo-registry в DigitalOcean, это выглядело бы так:<br>
docker tag \\<br>    <4s>habr-app-demo/backend:latest \<br>    <4s>registry.digitalocean.com/habr-app-demo-registry/backend<br>docker push \\<br>    <4s>registry.digitalocean.com/habr-app-demo-registry/backend<br>
# Теперь можно использовать<br>#     <4s>registry.digitalocean.com/habr-app-demo-registry/backend:latest<br># как название образа в описании пода.<br># Аналогично для двух других образов.<br>
Перед деплоем нужно задать параметры для Deployment, чтобы пользоваться им, а не создавать Поды руками.<br>
Там нужно внести а) количество желаемых подов б) шаблон,  по которому их нужно клепать + (опционально) настройки той самой плавной выкатки — например, какое максимальное количество подов может быть в переходном состоянии в каждый момент времени.<br>
kubectl apply -f k8s/backend-deployment.yaml<br>
Настраиваем роутинг<br>
В настройках есть параметры:<br>  <4s>* requests и limits - по CPU.<br><4s>* Настройка плавной выкатки: тут можно настроить в % сколько подов может быть впереходном состоянии и сколько лишних подов может существовать.
<br><4s>* Liveness-пробы<br> <4s>* HorizontalPodAutoscaler<br> <4s>* Джобы для сложных ЦПУ задач.
    `},
        5: {'question': 'Kibana / Grafana', 'answer': `Kibana - ЛОГИРОВАНИЕ<br>Используется вместе с Elasticsearch для хранения, поиска и анализа больших объемов данных (ELK) для визуализации данных - Дашбордов<br><br>
                Grafana - Метрики, графики.`},
        6: {'question': 'cron', 'answer': `Сервис для периодического, настраиваемого на определенное расписание, выполнения задач, например рассылка, сбор инфы с сайта (лайки например).<br><br>

можно реализовать через стандартный модуль CRON, через библиотеку SCHEDULE, либо через настройку линукс (там есть конфигурационные файлы для запуска скрипта,<br><br>
запись времени выполнения скрипта в отдельный файл, если машина выключится, то расписание не собьется, есть отдельные файлы с логами.<br><br>
тема с рассылкой расписания на день (или другой ежедневной информацией)) в телегу утром<br><br>
import schedule<br>
import time<br><br>
def my_job():<br>
    <4s>print("Выполняю периодическую задачу")<br><br>
# Запускаем задачу каждую минуту<br>
schedule.every(1).minutes.do(my_job)<br><br>
# Запускаем задачу каждый час<br>
# schedule.every().hour.do(my_job)<br><br>
# Запускаем задачу каждый день в 12:00 (Есть вариант - ДЕНЬ НЕДЕЛИ)<br>
# schedule.every().day.at("12:00").do(my_job)<br><br>
# Запускаем планировщик в фоновом режиме<br>
while True:<br>
    <4s>schedule.run_pending()<br>
    <4s>time.sleep(1)`},
        7: {'question': 'NGINX',
            'answer': `Разработчики Python используют NGINX в нескольких сценариях, особенно когда речь идет о веб-разработке и развертывании веб-приложений. Вот некоторые из основных способов, которыми они могли бы использовать NGINX:<br><br>
В качестве веб-сервера: NGINX — это высокопроизводительный веб-сервер, который может обслуживать статические файлы (например, HTML, CSS, JavaScript), обеспечивая быструю загрузку веб-страниц.<br><br>
Как прокси-сервер: NGINX часто используется в качестве обратного прокси-сервера, который принимает HTTP-запросы от клиентов и перенаправляет их на один или несколько бэкенд-серверов
(например, приложения на Flask или Django), управляет балансировкой нагрузки и предоставляет кеширование для повышения производительности.<br><br>
Для SSL/TLS терминации: NGINX может управлять шифрованием и дешифрованием трафика SSL/TLS, обеспечивая безопасные соединения между конечными пользователями и веб-сервером.<br><br>
Балансировка нагрузки: NGINX способен распределять входящий трафик между несколькими серверами приложений, тем самым улучшая общую пропускную способность и надежность ресурса.<br><br>
Управление конфигурацией: Разработчики могут настраивать NGINX с помощью его мощных конфигурационных файлов, управляя поведением веб-сервера под различные нужды приложения.<br><br>
Интеграция с контейнерами Docker: NGINX часто используется в контейнеризированных средах для направления трафика к приложениям в контейнерах, обеспечивая бесперебойное взаимодействие и масштабирование.<br><br>
Микросервисная архитектура: В архитектуре микросервисов NGINX может выступать в роли шлюза к микросервисам, управляя безопасностью, балансировкой нагрузки и маршрутизацией между различными сервисами.`},
        8: {'question': 'CI/CD', 'answer': `Позволяют чаще и надежнее развертывать ПО.<br><br>
continuous integration - непрерывная интеграция - для того, чтобы заливать код с новыми фичами в проект, а затем это всё это дело должно автоматически собираться, тестироваться, развертываться.<br>
По сути - это часть процесса, когда наши изменения заливаются в общий репозиторий и у нас запускается автоматическая сборка, различные валидаторы и тесты,
чтобы убедиться, что наш код интегрируется, ничего не крашнет в действующем проекте.(гитлаб сиай, дженкинс, гит экшнс, бамбу, серкл сиай, тим сити)<br><br>
continuous delivery - непрерывная доставка - для доставки оттестированных фич до конечных пользователей. (докер, кубернитис, энсибл, терраформ)<br>
continuous deployment<br><br>

pipeline - например, можно настроить так, чтобы когда мы заливаем код в определенную ветку, запускается процесс сборки, тесты, а после успешного прохождения прил. развертывается на определенном серваке.<br>
-в проекте создаем файл с ресширением ямл<br>
-там прописываем сначала стадии stages (-start, -begin, -finish), потом расшиваем подробнее каждое "действие" с привязкой к стадии, имеджу<br>
-есть before и after скрипты, которые можно определять как глобально, так и для каждой задачи отдельно<br>
-есть переменные для настройки:<br>
* only - задаем условия для выполнения задачи<br>
* except - условия НЕвыполнения задачи<br>
* when - выполнять задачу по условию (например разрешение оператора), по умолчанию задача выполняется, если завершилась предыдущая<br><br>
GitLab на сервак:<br><br>
сервер взял, есть айпи, купил домен, дальше все по документации поднимаешь через линукс, создаешь гитлаб, <br>зашли по урлу, вводишь креды (root и пароль можно либо задать, либо посмотреть пароль по ссылке, её даст в процессе),<br>
создаешь проект (как гитхаб),<br> клонируешь репу, <br>устанавливаешь ранер через консоль, <br>на гитлаб регистрируешь новый ранер и настраиваешь (тег / антег),<br> далее создаем управляющий ямл файл, описываем там задачи, <br>
далее по пушу в ветку, он будет выполнять пайплайн и отражать результаты на гитлаб.`},
        9: {'question': 'Объяснение концепции Serverless: Что такое вычисления без сервера (serverless computing)? ',
            'answer': `Использование "облачных" технологий для запуска приложений вместо докера и виртуальных машин:<br><br>
            Особенности концепции:<br>
абстракция инфраструктуры - разраб работает с функциями или сервисами, а не с серверами и сетевыми настройками<br>
событийно-ориентированная архитектура - функции запускаются в ответ на какие-либо события, http запросы, обновления бд, загрузку файла итд<br>
оплата за фактически использованные ресурсы<br>
масштабирование по требованию`},
        10: {'question': 'Распределенные транзакции', 'answer': `Если у нас монолит - относительно работы с БД, то вопросов нет - в плане транзакции, роллбека и тд.<br>
                А если у нас несколько микросервисов ходят в несколько разных БД, то встает вопрос как их синхронизировать.<br>
                Например Клиент бронирует Номер в гостинице и Машину, нужно защитить эту транзакцию.<br>
                SAGA - тут пользуемся ей.<br>
                Есть несколько вариантов: 1. Создавать контроллер, который даёт всем команду проверки готовности, ждет от всех ответа ОК, если все ОК, то дает команду на камит, если нет то все роллбек. - не нравится, много запросов и он сам может лечь!<br>
                2. Без контроллера - сервисы поочередно выполняют операции и отчитываются следующему, если ОК, то он начинает выполенние, если какой-то не ОК, то запускается общий роллбек.<br>
                Паттерн - Transactional outbox.<br>
                Весь ACID кроме Изоляции - тут реализован`},
        11: {'question': 'ДЛЯ ВСТАВКИ',
            'answer': ``},
        12: {'question': 'ДЛЯ ВСТАВКИ',
            'answer': ``},
    },
}

var mainText = `
    Совет №0: работает?.
    <br><br>
    Совет №1: если крутите опыт, то очень хорошо проработайте легенду, посмотрите телеграм-канал "Один день ITшника",
    поспрашивайте опытных товарищей.
    <br><br>
    Совет №2: чем учить теорию до бесконечности выучите поверхностно любой список вопросов из интернета (топ 50 вопросов
    по вашему языку, топ 50 вопросов по вашему фреймворку) и идите практиковаться проходить собесы. За 5-6 собесов
    поймёте, что спрашивают 20-30 одних и тех же вопросов, выпишите их все и те что не знаете выучите.
    <br><br>
    Совет №3: включайте запись с экрана когда проходите техническое собеседование. Телефонные созвоны с эйчарами
    тоже желательно записывать. Потом отсматривайте/отслушивайте, выписывайте вопросы что задают, обращайте
    внимание как вы сами отвечаете, корректируйте свои ответы. Найдите оптимальный темп ответа: слишком быстрые
    ответы будут выглядеть как заученные, при слишком долгих размышлениях будете выглядеть неуверенно. Идеально
    знать ответ на вопрос и делать вид, что слегка задумался, а потом постепенно выдавать ответ, будто вспоминаешь.
    Ещё одна хитрость - старайтесь растягивать ответ, можно уйти в рассуждения, углубить ответ, затронуть другие темы,
    скорее всего собеседующий вас сразу же не прервёт и вы выиграете драгоценное время, ведь нам важно, чтобы за
    собеседование нам задали как можно меньше вопросов, а собеседование не резиновое.
    <br><br>
    Совет №4: на скрининге помимо общих вопросов эйчары могут поспрашивать технические вопросы по бумажке, либо
    тест с вариантами ответов, нужно быть к этому готовым. Твои ответы будут оценивать не они, они запишут ответы
    либо текстом, либо на аудио.
    <br><br>
    Совет №5: не ставьте на один день больше 2 технических собеседований, лучше вообще 1. Скринингов это не касается,
    можно и 5 штук поставить.
    <br><br>
    Совет №6: обязательно просить фидбек в конце интервью, даже если чувствуешь, что провалил его. Если после
    эйчар напишет отказ без фидбека тоже попросить обратную связь. Если всё же не получишь обратную связь, то не
    стоит загоняться по поводу причины отказа, причины могут быть совершенно разные:<br>
    - недостаточные знания<br>
    - не устроила причина твоего увольнения с последнего места работы<br>
    - в резюме слишком частые смены работ<br>
    - вакансия уже закрылась (хотя эту причину обычно озвучивают)<br>
    - ты попросил слишком много денег<br>
    - не понравилась твоя внешность<br>
    - не понравилась твоя манера общения<br>
    - не понравились твои взгляды на работу<br>
    - не подошёл твой предыдущий опыт (искали кандидата с релевантным опытом, например в банковской сфере)<br>
    - не совпали по твоим ожиданиям от работы и то что они могут предложить
    <br><br>
    Совет №7: обращайте внимание на красные флаги. Например:<br>
    - вакансия очень долго открыта<br>
    - не хотят говорить вилку по зарплате<br>
    - очень размытые требования к кандидату<br>
    - сфера деятельности компании из серого списка (ставки на спорт, сайты для взрослых, казино, микрозаймы)<br>
    - оформление по ГПХ или как самозанятый<br>
    - стартап, который оплачивает работу акциями
    <br><br>
    Совет №8: когда будете с эйчаром выбирать дату техсобеса, выбирайте день как можно раньше. Выучить что-то за несколько
    дней в любом случае не успеете, а вот потерять вакансию шансы увеличиваются.
    <br><br>
    Совет №9: не стоит переоценивать знание фреймворков, довольно редко задают вопросы на знание конкретного фреймворка
    и даже если спросят, то скорее всего какие то поверхностные вопросы. Чаще спрашивают фундаментальные вопросы:
    базы данных, асинхронность, знание языка.
    <br><br>
    Совет №10: не приходите на собеседование уставшим, в состоянии опьянения, в плохом самочувствии, лучше в
    таком случае объясниться и попросить перенести встречу.
    <br><br>
    Совет №11: если не знаете ответа, то не нужно мяться и делать долгих пауз, лучше сказать честно, что либо
    забыл, либо не сталкивался с таким в работе, но попробуешь порассуждать. Обращают внимание как ты отвечаешь
    на вопросы на которые не знаешь ответа, пробуешь ли рассуждать, смотрят за логикой рассуждений.
    <br><br>
    Совет №12: обязательно задавайте вопросы эйчару, отсутствие вопросов может произвести впечатление, что ты
    не сильно заинтересован в вакансии.
    <br><br>
    Совет №13: не спорьте с собеседующим, за исключением случаев, когда в задании ошибка. Даже если вы при нём загуглите
    и докажите что он неправ в реальности это скорее вызовет у него обиду, нежели восхищение какой вы умный и инициативный
    и умеете отстаивать свою точку зрения. Это не касается случаев, когда сам собеседующий приглашает подискутировать.
`